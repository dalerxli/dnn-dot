{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"thesis2.ipynb","provenance":[{"file_id":"1_fl6WRDCnwSSVJPKXp3yPiTwYYd0Y_k3","timestamp":1578883234875}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EchhwRUwN7RD","colab_type":"code","outputId":"6055c5b9-9a31-4088-9f8c-00b359065035","executionInfo":{"status":"ok","timestamp":1578919870643,"user_tz":-480,"elapsed":22803,"user":{"displayName":"代安語","photoUrl":"","userId":"02683702717166278139"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XOt91hvP9Gzr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6874706e-bab9-4cd7-cedd-f1c0efead6fe","executionInfo":{"status":"ok","timestamp":1578926315971,"user_tz":-480,"elapsed":979,"user":{"displayName":"代安語","photoUrl":"","userId":"02683702717166278139"}}},"source":["%cd '/content/drive/My Drive/Workspace Riset Tata/thesis'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Workspace Riset Tata/thesis\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2P4yvHx1XEFz","colab_type":"code","outputId":"33e2c918-aebf-4051-da7a-037c07b8868c","executionInfo":{"status":"ok","timestamp":1578888700122,"user_tz":-480,"elapsed":2581,"user":{"displayName":"代安語","photoUrl":"","userId":"02683702717166278139"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%cd '/content/drive/My Drive/Workspace Riset Tata/thesis'\n","import config_16x15_seq\n","%cd '/content/drive/My Drive/Workspace Riset Tata/thesis/config_16x15_seq'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/thesis\n","/content/drive/My Drive/thesis/config_16x15_seq\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rs_DcUTNXNNg","colab_type":"code","outputId":"a581b9c8-45c9-4800-ac7d-5b3178fca281","executionInfo":{"status":"ok","timestamp":1578920520317,"user_tz":-480,"elapsed":1869,"user":{"displayName":"代安語","photoUrl":"","userId":"02683702717166278139"}},"colab":{"base_uri":"https://localhost:8080/","height":97}},"source":["import os\n","import pprint\n","import tensorflow as tf\n","\n","if 'COLAB_TPU_ADDR' not in os.environ:\n","    device_name = tf.test.gpu_device_name()\n","    if device_name != '/device:GPU:0':\n","        print('ERROR!')\n","    else:\n","        print('Found GPU at: {}'.format(device_name))\n","else:\n","    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","    print('TPU address is', tpu_address)\n","    with tf.Session(tpu_address) as session:\n","        devices = session.list_devices()\n","        print('TPU devices:')\n","        pprint.pprint(devices)\n","\n"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wqojsneLXlfE","colab_type":"code","outputId":"4c8efe98-8578-4bcf-e906-de62e3b4009d","executionInfo":{"status":"ok","timestamp":1578909946105,"user_tz":-480,"elapsed":21235172,"user":{"displayName":"代安語","photoUrl":"","userId":"02683702717166278139"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from config_16x15_seq.builder import *\n","from tqdm import tqdm\n","from keras.callbacks import BaseLogger, History, CallbackList\n","from scipy.ndimage import gaussian_filter\n","import copy\n","\n","MU_training = MU['training']\n","MU_norm_training = MU_norm['training']\n","PHI_meas_training = PHI_meas['training']\n","MUa_training = MUa['training']\n","MUsp_training = MUsp['training']\n","freq_training = freq['training']\n","d_training = d['training']\n","lr = 0.0002\n","beta_1 = 0.5\n","# clip_value = 0.01\n","optimizer = Adam(lr=lr, beta_1=beta_1)\n","# optimizer = RMSprop(lr=lr)\n","generator = primary_net()\n","print('Generator model summary:')\n","generator.summary()\n","discriminator = secondary_net()\n","discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[custom_binary_accuracy])\n","print('Discriminator model summary:')\n","discriminator.summary()\n","discriminator.trainable = False\n","# inputs = Input((PHI_meas_training.shape[1],))\n","outputs = generator.outputs\n","outputs.append(discriminator(outputs[:2]))\n","gan = Model(inputs=generator.inputs, outputs=outputs)\n","loss = ['mse', 'mse', 'mse', 'mse', 'mse', 'mse', 'binary_crossentropy']\n","loss_weights = [0, 0, 5, 5, 1e4, 1, 1]\n","metrics = ['mae', 'mse', 'mape', 'msle', 'logcosh', 'cosine', custom_binary_accuracy]\n","gan.compile(loss=loss, loss_weights=loss_weights, optimizer=optimizer, metrics=metrics)\n","print('Generative adversarial network model summary:')\n","gan.summary()\n","history = History()\n","logger = BaseLogger(stateful_metrics=['discriminator_' + s for s in discriminator.stateful_metric_names] +\n","                                     ['gan_' + s for s in gan.stateful_metric_names])\n","# checkpoint = callbacks.ModelCheckpoint('model_test{epoch:02d}.h5', verbose=1)\n","time_history = TimeHistory()\n","callbacks = [logger, time_history, history]\n","out_labels = ['discriminator_' + s for s in discriminator.metrics_names] + ['gan_' + s for s in gan.metrics_names]\n","callback_metrics = copy.copy(out_labels) + ['val_' + n for n in out_labels]\n","callbacks = CallbackList(callbacks)\n","# callbacks = [TimeHistory(), EarlyStopping(monitor='loss', min_delta=0.1, patience=100,\n","#                                           restore_best_weights=True, verbose=1)]\n","# early_stop = EarlyStopping(patience=200, verbose=1)\n","choice = np.zeros(data_size, dtype='uint8')\n","choice[np.random.choice(data_size, val_size, replace=False)] = 1\n","MU_training_train = MU_training[choice == 0]\n","MU_training_val = MU_training[choice == 1]\n","MU_norm_training_train = MU_norm_training[choice == 0]\n","MU_norm_training_val = MU_norm_training[choice == 1]\n","PHI_meas_training_train = PHI_meas_training[choice == 0]\n","PHI_meas_training_val = PHI_meas_training[choice == 1]\n","freq_training_train = freq_training[choice == 0]\n","freq_training_val = freq_training[choice == 1]\n","d_training_train = d_training[choice == 0]\n","d_training_val = d_training[choice == 1]\n","MUa_train = MUa_training[choice == 0]\n","MUa_val = MUa_training[choice == 1]\n","MUsp_train = MUsp_training[choice == 0]\n","MUsp_val = MUsp_training[choice == 1]\n","# choice = data_cat\n","batch_size = 32\n","prob_param = 20.0\n","prob_param2 = 1.0\n","# label_softness = 0.1\n","# metrics_eval_n = 50\n","# metrics_eval_step = 20\n","hard_valid = np.ones(val_size)\n","hard_fake = np.zeros(val_size)\n","\n","\n","# soft_label = False\n","# augment = True\n","# min_img_loss_avg = np.inf\n","# min_dis_loss_avg = np.inf\n","# img_loss_baseline_factor = 1.1\n","# img_loss_threshold = 1.2\n","# img_loss_threshold2 = 0.6\n","# prob_augment = 0.5\n","# gan_d_acc = [0.5, 0.5]\n","# init_train = 100\n","\n","N_count_train = np.zeros_like(N_count)\n","n = 0\n","for i in range(len(N_count)):\n","    ni = N_count[i]\n","    N_count_train[i] = np.where(choice[n:(n + ni)] == 0)[0].size\n","    n += ni\n","index_array = np.arange(train_size)\n","index_array2 = np.arange(train_size)\n","ia = np.arange(train_size)\n","n = N_count_train[0]\n","np.random.shuffle(index_array[:n])\n","np.random.shuffle(index_array2[:n])\n","for i in range(1, len(N_count_train) - 1):\n","    ni = N_count_train[i]\n","    np.random.shuffle(index_array[n:(n + ni)])\n","    np.random.shuffle(index_array2[n:(n + ni)])\n","    n += ni\n","np.random.shuffle(index_array[n:])\n","np.random.shuffle(index_array2[n:])\n","\n","\n","def run_epoch(epochs):\n","    callbacks.set_params({\n","        'batch_size': batch_size,\n","        'epochs': epochs,\n","        'steps': None,\n","        'samples': train_size,\n","        'verbose': 2,\n","        'do_validation': True,\n","        'metrics': callback_metrics,\n","    })\n","    callbacks.on_train_begin()\n","    for epoch in range(epochs):\n","        for m in discriminator.stateful_metric_functions:\n","            m.reset_states()\n","        for m in gan.stateful_metric_functions:\n","            m.reset_states()\n","        callbacks.on_epoch_begin(epoch)\n","        epoch_logs = {}\n","        progress_bar = None\n","        # np.random.shuffle(ia)\n","        n = N_count_train[0]\n","        np.random.shuffle(ia[:n])\n","        for i in range(1, len(N_count_train) - 1):\n","            ni = N_count_train[i]\n","            np.random.shuffle(ia[n:(n + ni)])\n","            n += ni\n","        np.random.shuffle(ia[n:])\n","        num_batches = (train_size + batch_size - 1) // batch_size\n","        # if epoch > 0 and epoch % metrics_eval_step == 0:\n","        # hist_avg = {}\n","        # for k, v in history.history.items():\n","        #     if k.startswith('val_'):\n","        #         l = k[4:]\n","        #     else:\n","        #         l = k\n","        #     if l in logger.stateful_metrics:\n","        #         hist_avg[k] = v[-1]\n","        #     else:\n","        #         hist_avg[k] = np.average(v[-metrics_eval_n:])\n","        # img_loss_avg = hist_avg['val_gan_' + gan.metrics_names[0]] - hist_avg['val_gan_' + gan.metrics_names[7]]\n","        # dis_loss_avg = hist_avg['val_discriminator_' + discriminator.metrics_names[0]]\n","        # min_img_loss = np.min(history.history['val_gan_' + gan.metrics_names[0]]) \\\n","        #                - np.min(history.history['val_gan_' + gan.metrics_names[7]])\n","        # if img_loss_avg > min_img_loss_avg * img_loss_baseline_factor:\n","        #     if not augment:\n","        #         augment = True\n","        #     elif img_loss_avg >= img_loss_threshold and min_img_loss >= img_loss_threshold2:\n","        #         soft_label = True\n","        # elif dis_loss_avg > min_dis_loss_avg:\n","        #     if augment:\n","        #         augment = False\n","        #     elif img_loss_avg < img_loss_threshold:\n","        #         soft_label = False\n","        # img_loss_avg = np.average(history.history['val_gan_' + gan.metrics_names[0]][-metrics_eval_n:])\\\n","        #                - np.average(history.history['val_gan_' + gan.metrics_names[7]][-metrics_eval_n:])\n","        # if soft_label and img_loss_avg < img_loss_threshold:\n","        #     soft_label = False\n","        # if np.random.random() > 0.5:\n","        #     augment = not augment\n","        # min_img_loss_avg = min(img_loss_avg, min_img_loss_avg)\n","        # min_dis_loss_avg = min(dis_loss_avg, min_dis_loss_avg)\n","        # if epoch >= init_train:\n","        #     if gan_d_acc[0] < 0.5 or gan_d_acc[1] < 0.5:\n","        #         prob_augment = 0.8\n","        #     else:\n","        #         prob_augment = 0.5\n","        #     if augment == (np.random.random() < prob_augment):\n","        #         augment = not augment\n","        batch_end = 0\n","        # prob_augment = np.random.random()\n","        for batch_index in range(num_batches):\n","            augment = np.random.random() < 0.5\n","            batch_start = batch_end\n","            batch_end = min(train_size, batch_end + batch_size)\n","            batch_ids = index_array[ia[batch_start:batch_end]]\n","            batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n","            callbacks.on_batch_begin(batch_index, batch_logs)\n","            MU_gt = [MU_training_train[batch_ids, 0], MU_training_train[batch_ids, 1]]\n","            MU_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_gt]\n","            in_gen = [PHI_meas_training_train[batch_ids], freq_training_train[batch_ids], d_training_train[batch_ids]]\n","            if augment:\n","                noise_param = np.random.random(len(batch_ids))\n","                blur_param = np.random.random(len(batch_ids))\n","                noise_param *= blur_param\n","                MU_gt_aug = [np.copy(im) for im in MU_gt]\n","                for i, bi in enumerate(batch_ids):\n","                    temp = mask_image(MU_gt_aug[0][i, 0], MUa_train[bi])\n","                    temp = temp + temp * np.random.normal(scale=noise_param[i] * 0.5, size=temp.shape)\n","                    temp = gaussian_filter(temp, blur_param[i] * 5.0)\n","                    MU_gt_aug[0][i, 0] = mask_image(temp, 0.0)\n","                    temp = mask_image(MU_gt_aug[1][i, 0], MUsp_train[bi])\n","                    temp = temp + temp * np.random.normal(scale=noise_param[i] * 0.5, size=temp.shape)\n","                    temp = gaussian_filter(temp, blur_param[i] * 5.0)\n","                    MU_gt_aug[1][i, 0] = mask_image(temp, 0.0)\n","                # temp = np.clip(blur_param, prob_param2 / prob_param, 1.0 - prob_param2 / prob_param)\n","                valid = 0.95 - 0.05 * np.random.random(len(batch_ids))\n","                # valid = 1.0 - label_softness * np.random.beta(temp * prob_param, (1.0 - temp) * prob_param)\n","                # if soft_label:\n","                #     fake = label_softness * np.random.random(len(batch_ids))\n","                #     valid = 1.0 - label_softness * np.random.beta(temp * prob_param, (1.0 - temp) * prob_param)\n","                # else:\n","                #     fake = hard_fake[:len(batch_ids)]\n","                #     valid = hard_valid[:len(batch_ids)] - label_softness\n","            else:\n","                MU_gt_aug = MU_gt\n","                valid = hard_valid[:len(batch_ids)] - 0.05\n","                # valid = 1.0 - 0.05 * np.random.random(len(batch_ids))\n","                # valid = 1.0 - label_softness * np.random.random(len(batch_ids))\n","                # valid = 1.0 - label_softness * np.random.beta(prob_param2,\n","                #                                               prob_param - prob_param2, size=len(batch_ids))\n","                # if soft_label:\n","                #     fake = label_softness * np.random.random(len(batch_ids))\n","                #     valid = 1.0 - label_softness * np.random.beta(\n","                #         prob_param2, prob_param - prob_param2, size=len(batch_ids))\n","                # else:\n","                #     fake = hard_fake[:len(batch_ids)]\n","                #     valid = hard_valid[:len(batch_ids)] - label_softness\n","            # fake = hard_fake[:len(batch_ids)]\n","            fake = 0.05 * np.random.random(len(batch_ids))\n","            # if epoch < init_train:\n","            #     valid -= label_softness * np.random.random(len(batch_ids)) * (init_train - epoch) / init_train\n","            #     fake += label_softness * np.random.random(len(batch_ids)) * (init_train - epoch) / init_train\n","            d_loss1 = discriminator.train_on_batch(MU_gt_aug, valid)\n","            # d_loss1 = discriminator.train_on_batch([np.concatenate([im1, im2], axis=0)\n","            #                                        for im1, im2 in zip(MU_gt_aug, MU_gt)],\n","            #                                        np.concatenate([valid, hard_valid[:len(batch_ids)]], axis=0),\n","            #                                        sample_weight=np.ones(2 * len(batch_ids)) * 0.5)\n","            d_loss2 = discriminator.train_on_batch(generator.predict(in_gen)[:2], fake)\n","            # d_loss = discriminator.train_on_batch([np.concatenate([im1, im2], axis=0)\n","            #                                        for im1, im2 in zip(MU_gt_aug, generator.predict(in_gen)[:2])],\n","            #                                       np.concatenate([valid, fake], axis=0))\n","            d_loss = np.zeros(len(discriminator.metrics_names))\n","            for i, l in enumerate(discriminator.metrics_names):\n","                if l in discriminator.stateful_metric_names:\n","                    d_loss[i] = d_loss2[i]\n","                else:\n","                    d_loss[i] = 0.5 * (d_loss1[i] + d_loss2[i])\n","            # for l in discriminator.layers:\n","            #     weights = l.get_weights()\n","            #     weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n","            #     l.set_weights(weights)\n","            batch_ids = index_array2[ia[batch_start:batch_end]]\n","            MU_gt = [MU_training_train[batch_ids, 0], MU_training_train[batch_ids, 1]]\n","            MU_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_gt]\n","            in_gen = [PHI_meas_training_train[batch_ids], freq_training_train[batch_ids], d_training_train[batch_ids]]\n","            MU_norm_gt = [MU_norm_training_train[batch_ids, 0], MU_norm_training_train[batch_ids, 1]]\n","            MU_norm_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_norm_gt]\n","            g_loss = gan.train_on_batch(in_gen, [MU_gt[0], MU_gt[1], MU_norm_gt[0], MU_norm_gt[1],\n","                                                 MUa_train[batch_ids], MUsp_train[batch_ids],\n","                                                 hard_valid[:len(batch_ids)]])\n","            for l, o in zip(out_labels, np.concatenate([d_loss, g_loss])):\n","                batch_logs[l] = o\n","            callbacks.on_batch_end(batch_index, batch_logs)\n","            if progress_bar is None:\n","                progress_bar = tqdm(total=train_size, desc='Epoch {}/{}'.format(epoch + 1, epochs), unit='samples')\n","            progress_bar.set_postfix(train_on_batch=('[D loss: [%g %g], acc.: [%.2f%% %.2f%%]] [G total_loss: %g, ' +\n","                                                     'img_loss: %g, d_loss: %g, d_acc.: %.2f%%]') %\n","                                                    (d_loss1[0], d_loss2[0], 100 * d_loss1[1], 100 * d_loss2[1],\n","                                                     g_loss[0],\n","                                                     g_loss[0] - g_loss[7], g_loss[7], 100 * g_loss[-1]),\n","                                     augment=augment)\n","            progress_bar.update(len(batch_ids))\n","        MU_gt = [MU_training_val[:, np.array([0])], MU_training_val[:, np.array([1])]]\n","        d_val_loss1 = discriminator.evaluate(MU_gt, hard_valid, batch_size=batch_size, verbose=0)\n","        d_val_loss2 = discriminator.evaluate(generator.predict([PHI_meas_training_val, freq_training_val,\n","                                                                d_training_val])[:2], hard_fake, batch_size=batch_size,\n","                                             verbose=0)\n","        # d_val_loss = discriminator.evaluate([np.concatenate([im1, im2], axis=0)\n","        #                                      for im1, im2 in zip(MU_gt,\n","        #                                                          generator.predict(PHI_meas_training_val)[:2])],\n","        #                                     np.concatenate([hard_valid, hard_fake], axis=0), verbose=0)\n","        d_val_loss = np.zeros(len(discriminator.metrics_names))\n","        for i, l in enumerate(discriminator.metrics_names):\n","            if l in discriminator.stateful_metric_names:\n","                d_val_loss[i] = d_val_loss2[i]\n","            else:\n","                d_val_loss[i] = 0.5 * (d_val_loss1[i] + d_val_loss2[i])\n","        MU_norm_gt = [MU_norm_training_val[:, np.array([0])], MU_norm_training_val[:, np.array([1])]]\n","        progress_bar.set_postfix(validate_on_epoch='[D loss: [%g %g], acc.: [%.2f%% %.2f%%]] validating generator..' %\n","                                                   (d_val_loss1[0], d_val_loss2[0], 100 * d_val_loss1[1],\n","                                                    100 * d_val_loss2[1]))\n","        g_val_loss = gan.evaluate([PHI_meas_training_val, freq_training_val, d_training_val],\n","                                  [MU_gt[0], MU_gt[1], MU_norm_gt[0], MU_norm_gt[1], MUa_val, MUsp_val, hard_valid],\n","                                  batch_size=batch_size, verbose=0)\n","        for l, o in zip(out_labels, np.concatenate([d_val_loss, g_val_loss])):\n","            epoch_logs['val_' + l] = o\n","        # num_batches = (val_size + batch_size - 1) // batch_size\n","        # for batch_index in range(num_batches):\n","        #     batch_start = batch_index * batch_size\n","        #     batch_end = min(val_size, (batch_index + 1) * batch_size)\n","        #     MU_gt = [MU_training_val[batch_start:batch_end, 0], MU_training_val[batch_start:batch_end, 0]]\n","        #     MU_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_gt]\n","        #     d_loss1 = discriminator.test_on_batch(MU_gt, hard_valid[:(batch_end - batch_start)])\n","        #     in_gen = PHI_meas_training_val[batch_start:batch_end]\n","        #     d_loss2 = discriminator.test_on_batch(generator.predict(in_gen)[:2], hard_fake[:(batch_end - batch_start)])\n","        #     d_loss = np.zeros(len(discriminator.metrics_names))\n","        #     for i, l in enumerate(discriminator.metrics_names):\n","        #         if l in discriminator.stateful_metric_names:\n","        #             d_loss[i] = d_loss2[i]\n","        #         else:\n","        #             d_loss[i] = 0.5 * (d_loss1[i] + d_loss2[i])\n","        #     MU_norm_gt = [MU_norm_training_val[batch_start:batch_end, 0],\n","        #                   MU_norm_training_val[batch_start:batch_end, 1]]\n","        #     MU_norm_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_norm_gt]\n","        #     g_loss = gan.test_on_batch(in_gen, [MU_gt[0], MU_gt[1], MU_norm_gt[0], MU_norm_gt[1],\n","        #                                       MUa_val[batch_start:batch_end], MUsp_val[batch_start:batch_end],\n","        #                                       hard_valid[:(batch_end - batch_start)]])\n","        #     for l, o in zip(out_labels, np.concatenate([d_loss, g_loss])):\n","        #         if l in logger.stateful_metrics:\n","        #             epoch_logs['val_' + l] = o\n","        #         else:\n","        #             if 'val_' + l in epoch_logs:\n","        #                 epoch_logs['val_' + l] += o * (batch_end - batch_start)\n","        #             else:\n","        #                 epoch_logs['val_' + l] = o * (batch_end - batch_start)\n","        #     pbar.set_postfix(validate_on_batch=('[D loss: %g, acc.: %.2f%%] [G total_loss: %g, img_loss: %g, ' +\n","        #                                         'd_loss: %g, d_acc.: %.2f%%]') %\n","        #                                        (d_loss[0], 100 * d_loss[1], g_loss[0], g_loss[0] - g_loss[7],\n","        #                                         g_loss[7], 100 * g_loss[-1]), soft_label=soft_label, augment=augment)\n","        #     pbar.update(batch_end - batch_start)\n","        # for l in out_labels:\n","        #     if l not in logger.stateful_metrics:\n","        #         epoch_logs['val_' + l] /= val_size\n","        callbacks.on_epoch_end(epoch, epoch_logs)\n","        # gan_d_acc[0] = epoch_logs[out_labels[-1]]\n","        # gan_d_acc[1] = epoch_logs['val_' + out_labels[-1]]\n","        progress_bar.set_postfix(train=('[D loss: %g, acc.: %.2f%%] [G total_loss: %g, img_loss: %g, d_loss: %g, ' +\n","                                        'd_acc.: %.2f%%]') %\n","                                       (epoch_logs[out_labels[0]], 100 * epoch_logs[out_labels[1]],\n","                                        epoch_logs[out_labels[2]],\n","                                        epoch_logs[out_labels[2]] - epoch_logs[out_labels[9]],\n","                                        epoch_logs[out_labels[9]],\n","                                        100 * epoch_logs[out_labels[-1]]),\n","                                 validation=('[D loss: %g, acc.: %.2f%%] [G total_loss: %g, img_loss: %g, ' +\n","                                             'd_loss: %g, d_acc.: %.2f%%]') %\n","                                            (epoch_logs['val_' + out_labels[0]],\n","                                             100 * epoch_logs['val_' + out_labels[1]],\n","                                             epoch_logs['val_' + out_labels[2]],\n","                                             epoch_logs['val_' + out_labels[2]] - epoch_logs['val_' + out_labels[9]],\n","                                             epoch_logs['val_' + out_labels[9]],\n","                                             100 * epoch_logs['val_' + out_labels[-1]]))\n","        progress_bar.close()\n","    callbacks.on_train_end()\n","    hist_data = {\n","        'train_start': time_history.train_time_start,\n","        'train_time': time_history.train_time,\n","        'epoch_time': time_history.times,\n","        'history': history.history,\n","        'choice': np.where(choice == 1)[0].tolist()\n","    }\n","    return hist_data\n","\n","\n","hist_data = run_epoch(100)\n","\n","gan.save('model46log_100.h5')\n","generator.save('model46log_100_gen.h5')\n","discriminator.save('model46log_100_dis.h5')\n","with open('model_hist_data46.0log.json', 'w') as f:\n","    json.dump(hist_data, f)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /content/drive/My Drive/thesis/config_16x15_seq/helper.py:54: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/thesis/config_16x15_seq/helper.py:56: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","Generator model summary:\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, 7)      0                                            \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, None, 6)      0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 512)          403968      lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 1)            0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 1)            0           input_3[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 514)          0           bidirectional_1[0][0]            \n","                                                                 lambda_3[0][0]                   \n","                                                                 lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 8192)         4218880     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 2, 64, 64)    0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 4, 64, 64)    76          reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 4, 64, 64)    16          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 4, 64, 64)    0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 4, 64, 64)    148         leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 4, 64, 64)    16          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 4, 64, 64)    0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 8, 32, 32)    520         leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 8, 32, 32)    32          conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 8, 32, 32)    0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 8, 32, 32)    584         leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 8, 32, 32)    32          conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 8, 32, 32)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 8, 32, 32)    584         leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 8, 32, 32)    32          conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 8, 32, 32)    0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 16, 16, 16)   2064        leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 16, 16, 16)   64          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 16)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 16, 16, 16)   2320        leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 16, 16, 16)   64          conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 16)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 16, 16, 16)   2320        leaky_re_lu_7[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 16, 16, 16)   64          conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 16)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 8, 8)     8224        leaky_re_lu_8[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 32, 8, 8)     128         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)       (None, 32, 8, 8)     0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 8, 8)     9248        leaky_re_lu_9[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 32, 8, 8)     128         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_10 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 8, 8)     9248        leaky_re_lu_10[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 8, 8)     128         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_11 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 64, 4, 4)     32832       leaky_re_lu_11[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 64, 4, 4)     256         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_12 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 64, 4, 4)     36928       leaky_re_lu_12[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 64, 4, 4)     256         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_13 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 64, 4, 4)     36928       leaky_re_lu_13[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 64, 4, 4)     256         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 32, 8, 8)     32800       leaky_re_lu_14[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 32, 8, 8)     128         conv2d_transpose_1[0][0]         \n","__________________________________________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 64, 8, 8)     0           leaky_re_lu_11[0][0]             \n","                                                                 leaky_re_lu_15[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 32, 8, 8)     18464       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 32, 8, 8)     128         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 32, 8, 8)     9248        leaky_re_lu_16[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 32, 8, 8)     128         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_2 (Conv2DTrans (None, 16, 16, 16)   8208        leaky_re_lu_17[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 16, 16, 16)   64          conv2d_transpose_2[0][0]         \n","__________________________________________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 32, 16, 16)   0           leaky_re_lu_8[0][0]              \n","                                                                 leaky_re_lu_18[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 16, 16, 16)   4624        concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 16, 16, 16)   64          conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 16, 16, 16)   2320        leaky_re_lu_19[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 16, 16, 16)   64          conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_3 (Conv2DTrans (None, 8, 32, 32)    2056        leaky_re_lu_20[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 8, 32, 32)    32          conv2d_transpose_3[0][0]         \n","__________________________________________________________________________________________________\n","leaky_re_lu_21 (LeakyReLU)      (None, 8, 32, 32)    0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 16, 32, 32)   0           leaky_re_lu_5[0][0]              \n","                                                                 leaky_re_lu_21[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 8, 32, 32)    1160        concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 8, 32, 32)    32          conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_22 (LeakyReLU)      (None, 8, 32, 32)    0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 8, 32, 32)    584         leaky_re_lu_22[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 8, 32, 32)    32          conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)      (None, 8, 32, 32)    0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_4 (Conv2DTrans (None, 4, 64, 64)    516         leaky_re_lu_23[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 4, 64, 64)    16          conv2d_transpose_4[0][0]         \n","__________________________________________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)      (None, 4, 64, 64)    0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 8, 64, 64)    0           leaky_re_lu_2[0][0]              \n","                                                                 leaky_re_lu_24[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 4, 64, 64)    292         concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 4, 64, 64)    16          conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)      (None, 4, 64, 64)    0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 4, 64, 64)    148         leaky_re_lu_25[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 4, 64, 64)    16          conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)      (None, 4, 64, 64)    0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 64)           32960       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 2, 64, 64)    10          leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 64)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 64)           32960       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 2, 64, 64)    0           reshape_1[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1)            65          leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 64)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 2, 64, 64)    0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 1)            0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1)            65          leaky_re_lu_28[0][0]             \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 2, 64, 64)    0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","repeat_vector_1 (RepeatVector)  (None, 4096, 1)      0           lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","repeat_vector_2 (RepeatVector)  (None, 4096, 1)      0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 1, 64, 64)    0           lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 1, 64, 64)    0           repeat_vector_1[0][0]            \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 1, 64, 64)    0           lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_3 (Reshape)             (None, 1, 64, 64)    0           repeat_vector_2[0][0]            \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 1, 64, 64)    0           lambda_7[0][0]                   \n","                                                                 reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_2 (Multiply)           (None, 1, 64, 64)    0           lambda_8[0][0]                   \n","                                                                 reshape_3[0][0]                  \n","==================================================================================================\n","Total params: 4,913,544\n","Trainable params: 4,912,448\n","Non-trainable params: 1,096\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Discriminator model summary:\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            (None, 1, 64, 64)    0                                            \n","__________________________________________________________________________________________________\n","input_5 (InputLayer)            (None, 1, 64, 64)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 16, 32, 32)   272         input_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 16, 32, 32)   272         input_5[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 16, 32, 32)   64          conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 16, 32, 32)   64          conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)      (None, 16, 32, 32)   0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_35 (LeakyReLU)      (None, 16, 32, 32)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 32, 16, 16)   8224        leaky_re_lu_29[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 32, 16, 16)   8224        leaky_re_lu_35[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 32, 16, 16)   128         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 32, 16, 16)   128         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_30 (LeakyReLU)      (None, 32, 16, 16)   0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_36 (LeakyReLU)      (None, 32, 16, 16)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 64, 8, 8)     32832       leaky_re_lu_30[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 64, 8, 8)     32832       leaky_re_lu_36[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 64, 8, 8)     256         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 64, 8, 8)     256         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_31 (LeakyReLU)      (None, 64, 8, 8)     0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_37 (LeakyReLU)      (None, 64, 8, 8)     0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 64, 4, 4)     65600       leaky_re_lu_31[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 64, 4, 4)     65600       leaky_re_lu_37[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 64, 4, 4)     256         conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 64, 4, 4)     256         conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_32 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_38 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 64, 2, 2)     65600       leaky_re_lu_32[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 64, 2, 2)     65600       leaky_re_lu_38[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 64, 2, 2)     256         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 64, 2, 2)     256         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)      (None, 64, 2, 2)     0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_39 (LeakyReLU)      (None, 64, 2, 2)     0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 64, 1, 1)     65600       leaky_re_lu_33[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 64, 1, 1)     65600       leaky_re_lu_39[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 64, 1, 1)     256         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 64, 1, 1)     256         conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_34 (LeakyReLU)      (None, 64, 1, 1)     0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_40 (LeakyReLU)      (None, 64, 1, 1)     0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 64)           0           leaky_re_lu_34[0][0]             \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 64)           0           leaky_re_lu_40[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 128)          0           flatten_1[0][0]                  \n","                                                                 flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            129         concatenate_6[0][0]              \n","==================================================================================================\n","Total params: 478,817\n","Trainable params: 477,601\n","Non-trainable params: 1,216\n","__________________________________________________________________________________________________\n","Generative adversarial network model summary:\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, 7)      0                                            \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, None, 6)      0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 512)          403968      lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 1)            0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 1)            0           input_3[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 514)          0           bidirectional_1[0][0]            \n","                                                                 lambda_3[0][0]                   \n","                                                                 lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 8192)         4218880     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 2, 64, 64)    0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 4, 64, 64)    76          reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 4, 64, 64)    16          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 4, 64, 64)    0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 4, 64, 64)    148         leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 4, 64, 64)    16          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 4, 64, 64)    0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 8, 32, 32)    520         leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 8, 32, 32)    32          conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 8, 32, 32)    0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 8, 32, 32)    584         leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 8, 32, 32)    32          conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 8, 32, 32)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 8, 32, 32)    584         leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 8, 32, 32)    32          conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)       (None, 8, 32, 32)    0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 16, 16, 16)   2064        leaky_re_lu_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 16, 16, 16)   64          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 16)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 16, 16, 16)   2320        leaky_re_lu_6[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 16, 16, 16)   64          conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 16)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 16, 16, 16)   2320        leaky_re_lu_7[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 16, 16, 16)   64          conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 16)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 8, 8)     8224        leaky_re_lu_8[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 32, 8, 8)     128         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_9 (LeakyReLU)       (None, 32, 8, 8)     0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 8, 8)     9248        leaky_re_lu_9[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 32, 8, 8)     128         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_10 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 8, 8)     9248        leaky_re_lu_10[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 8, 8)     128         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_11 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 64, 4, 4)     32832       leaky_re_lu_11[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 64, 4, 4)     256         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_12 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 64, 4, 4)     36928       leaky_re_lu_12[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 64, 4, 4)     256         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_13 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 64, 4, 4)     36928       leaky_re_lu_13[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 64, 4, 4)     256         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 32, 8, 8)     32800       leaky_re_lu_14[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 32, 8, 8)     128         conv2d_transpose_1[0][0]         \n","__________________________________________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 64, 8, 8)     0           leaky_re_lu_11[0][0]             \n","                                                                 leaky_re_lu_15[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 32, 8, 8)     18464       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 32, 8, 8)     128         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 32, 8, 8)     9248        leaky_re_lu_16[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 32, 8, 8)     128         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)      (None, 32, 8, 8)     0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_2 (Conv2DTrans (None, 16, 16, 16)   8208        leaky_re_lu_17[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 16, 16, 16)   64          conv2d_transpose_2[0][0]         \n","__________________________________________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 32, 16, 16)   0           leaky_re_lu_8[0][0]              \n","                                                                 leaky_re_lu_18[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 16, 16, 16)   4624        concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 16, 16, 16)   64          conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 16, 16, 16)   2320        leaky_re_lu_19[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 16, 16, 16)   64          conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_3 (Conv2DTrans (None, 8, 32, 32)    2056        leaky_re_lu_20[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 8, 32, 32)    32          conv2d_transpose_3[0][0]         \n","__________________________________________________________________________________________________\n","leaky_re_lu_21 (LeakyReLU)      (None, 8, 32, 32)    0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 16, 32, 32)   0           leaky_re_lu_5[0][0]              \n","                                                                 leaky_re_lu_21[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 8, 32, 32)    1160        concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 8, 32, 32)    32          conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_22 (LeakyReLU)      (None, 8, 32, 32)    0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 8, 32, 32)    584         leaky_re_lu_22[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 8, 32, 32)    32          conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)      (None, 8, 32, 32)    0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_transpose_4 (Conv2DTrans (None, 4, 64, 64)    516         leaky_re_lu_23[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 4, 64, 64)    16          conv2d_transpose_4[0][0]         \n","__________________________________________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)      (None, 4, 64, 64)    0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 8, 64, 64)    0           leaky_re_lu_2[0][0]              \n","                                                                 leaky_re_lu_24[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 4, 64, 64)    292         concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 4, 64, 64)    16          conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)      (None, 4, 64, 64)    0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 4, 64, 64)    148         leaky_re_lu_25[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 4, 64, 64)    16          conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)      (None, 4, 64, 64)    0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 64)           32960       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 2, 64, 64)    10          leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 64)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 64)           32960       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 2, 64, 64)    0           reshape_1[0][0]                  \n","                                                                 conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1)            65          leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 64)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 2, 64, 64)    0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 1)            0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1)            65          leaky_re_lu_28[0][0]             \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 2, 64, 64)    0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","repeat_vector_1 (RepeatVector)  (None, 4096, 1)      0           lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","repeat_vector_2 (RepeatVector)  (None, 4096, 1)      0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 1, 64, 64)    0           lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 1, 64, 64)    0           repeat_vector_1[0][0]            \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 1, 64, 64)    0           lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_3 (Reshape)             (None, 1, 64, 64)    0           repeat_vector_2[0][0]            \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 1, 64, 64)    0           lambda_7[0][0]                   \n","                                                                 reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_2 (Multiply)           (None, 1, 64, 64)    0           lambda_8[0][0]                   \n","                                                                 reshape_3[0][0]                  \n","__________________________________________________________________________________________________\n","model_2 (Model)                 (None, 1)            478817      multiply_1[0][0]                 \n","                                                                 multiply_2[0][0]                 \n","==================================================================================================\n","Total params: 5,392,361\n","Trainable params: 4,912,448\n","Non-trainable params: 479,913\n","__________________________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","Epoch 1/100:   0%|          | 0/8000 [00:00<?, ?samples/s, augment=1, train_on_batch=[D loss: [0.695669 0.842798], acc.: [62.50% 28.12%]] [G total_loss: 8.04025, img_loss: 7.38172, d_loss: 0.658526, d_acc.: 62.50%]]/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","Epoch 1/100: 100%|██████████| 8000/8000 [03:35<00:00, 41.86samples/s, train=[D loss: 0.565002, acc.: 79.27%] [G total_loss: 9.90113, img_loss: 9.2278, d_loss: 0.673331, d_acc.: 62.69%], validation=[D loss: 0.698162, acc.: 49.60%] [G total_loss: 9.2765, img_loss: 8.65223, d_loss: 0.62427, d_acc.: 100.00%]]\n","Epoch 2/100: 100%|██████████| 8000/8000 [03:32<00:00, 41.77samples/s, train=[D loss: 0.417959, acc.: 96.22%] [G total_loss: 9.45518, img_loss: 8.76434, d_loss: 0.690842, d_acc.: 60.16%], validation=[D loss: 0.770975, acc.: 50.00%] [G total_loss: 9.11234, img_loss: 8.67432, d_loss: 0.438017, d_acc.: 100.00%]]\n","Epoch 3/100: 100%|██████████| 8000/8000 [03:29<00:00, 43.05samples/s, train=[D loss: 0.368824, acc.: 96.87%] [G total_loss: 9.59906, img_loss: 8.74905, d_loss: 0.850011, d_acc.: 42.96%], validation=[D loss: 0.79505, acc.: 49.98%] [G total_loss: 8.65448, img_loss: 8.25039, d_loss: 0.404089, d_acc.: 100.00%]]\n","Epoch 4/100: 100%|██████████| 8000/8000 [03:28<00:00, 41.88samples/s, train=[D loss: 0.36361, acc.: 96.62%] [G total_loss: 9.74909, img_loss: 8.72352, d_loss: 1.02556, d_acc.: 29.34%], validation=[D loss: 0.919598, acc.: 49.85%] [G total_loss: 9.45871, img_loss: 9.14592, d_loss: 0.312787, d_acc.: 100.00%]]\n","Epoch 5/100: 100%|██████████| 8000/8000 [03:29<00:00, 43.54samples/s, train=[D loss: 0.390155, acc.: 93.69%] [G total_loss: 9.57129, img_loss: 8.29254, d_loss: 1.27876, d_acc.: 16.89%], validation=[D loss: 0.905307, acc.: 49.80%] [G total_loss: 10.147, img_loss: 9.83561, d_loss: 0.311405, d_acc.: 100.00%]]\n","Epoch 6/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.51samples/s, train=[D loss: 0.436506, acc.: 87.78%] [G total_loss: 8.94416, img_loss: 7.66589, d_loss: 1.27827, d_acc.: 12.50%], validation=[D loss: 0.862174, acc.: 50.00%] [G total_loss: 9.47045, img_loss: 9.14158, d_loss: 0.32887, d_acc.: 100.00%]]\n","Epoch 7/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.04samples/s, train=[D loss: 0.414532, acc.: 89.68%] [G total_loss: 8.34761, img_loss: 7.34803, d_loss: 0.999582, d_acc.: 33.05%], validation=[D loss: 0.75798, acc.: 45.90%] [G total_loss: 7.68118, img_loss: 7.20286, d_loss: 0.478322, d_acc.: 100.00%]]\n","Epoch 8/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.12samples/s, train=[D loss: 0.406448, acc.: 88.94%] [G total_loss: 7.9294, img_loss: 7.04434, d_loss: 0.885065, d_acc.: 42.24%], validation=[D loss: 0.848083, acc.: 49.98%] [G total_loss: 6.72383, img_loss: 6.39595, d_loss: 0.327879, d_acc.: 100.00%]]\n","Epoch 9/100: 100%|██████████| 8000/8000 [03:29<00:00, 41.72samples/s, train=[D loss: 0.368061, acc.: 91.62%] [G total_loss: 7.29836, img_loss: 6.67303, d_loss: 0.625333, d_acc.: 67.00%], validation=[D loss: 1.22699, acc.: 50.00%] [G total_loss: 5.96138, img_loss: 5.80604, d_loss: 0.155349, d_acc.: 100.00%]]\n","Epoch 10/100: 100%|██████████| 8000/8000 [03:28<00:00, 42.60samples/s, train=[D loss: 0.333018, acc.: 92.95%] [G total_loss: 6.55908, img_loss: 6.08313, d_loss: 0.475943, d_acc.: 81.50%], validation=[D loss: 1.16297, acc.: 50.00%] [G total_loss: 5.81678, img_loss: 5.63375, d_loss: 0.183033, d_acc.: 100.00%]]\n","Epoch 11/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.47samples/s, train=[D loss: 0.295766, acc.: 94.50%] [G total_loss: 6.00542, img_loss: 5.63542, d_loss: 0.369999, d_acc.: 89.96%], validation=[D loss: 1.42564, acc.: 50.00%] [G total_loss: 5.54487, img_loss: 5.40983, d_loss: 0.135033, d_acc.: 100.00%]]\n","Epoch 12/100: 100%|██████████| 8000/8000 [03:29<00:00, 40.68samples/s, train=[D loss: 0.283234, acc.: 95.85%] [G total_loss: 5.61713, img_loss: 5.32175, d_loss: 0.295385, d_acc.: 93.47%], validation=[D loss: 1.78569, acc.: 50.00%] [G total_loss: 5.45377, img_loss: 5.35954, d_loss: 0.0942256, d_acc.: 100.00%]]\n","Epoch 13/100: 100%|██████████| 8000/8000 [03:28<00:00, 41.76samples/s, train=[D loss: 0.24169, acc.: 97.84%] [G total_loss: 5.38401, img_loss: 5.12364, d_loss: 0.260365, d_acc.: 95.49%], validation=[D loss: 1.59852, acc.: 50.00%] [G total_loss: 5.83947, img_loss: 5.72033, d_loss: 0.119142, d_acc.: 100.00%]]\n","Epoch 14/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.29samples/s, train=[D loss: 0.238459, acc.: 97.78%] [G total_loss: 5.17581, img_loss: 4.93717, d_loss: 0.238643, d_acc.: 95.53%], validation=[D loss: 1.15094, acc.: 50.00%] [G total_loss: 5.44521, img_loss: 5.26323, d_loss: 0.18198, d_acc.: 100.00%]]\n","Epoch 15/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.47samples/s, train=[D loss: 0.22709, acc.: 98.57%] [G total_loss: 5.01212, img_loss: 4.79714, d_loss: 0.214984, d_acc.: 96.80%], validation=[D loss: 1.17068, acc.: 50.00%] [G total_loss: 5.03773, img_loss: 4.85163, d_loss: 0.1861, d_acc.: 100.00%]]\n","Epoch 16/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.64samples/s, train=[D loss: 0.216465, acc.: 98.83%] [G total_loss: 4.84498, img_loss: 4.65877, d_loss: 0.186208, d_acc.: 97.52%], validation=[D loss: 1.53651, acc.: 50.00%] [G total_loss: 5.31307, img_loss: 5.19143, d_loss: 0.121642, d_acc.: 100.00%]]\n","Epoch 17/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.85samples/s, train=[D loss: 0.212879, acc.: 99.09%] [G total_loss: 4.78727, img_loss: 4.57505, d_loss: 0.212226, d_acc.: 95.99%], validation=[D loss: 1.57711, acc.: 50.00%] [G total_loss: 5.26592, img_loss: 5.161, d_loss: 0.104924, d_acc.: 100.00%]]\n","Epoch 18/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.74samples/s, train=[D loss: 0.217327, acc.: 98.71%] [G total_loss: 4.62106, img_loss: 4.44926, d_loss: 0.171804, d_acc.: 97.78%], validation=[D loss: 1.62614, acc.: 50.00%] [G total_loss: 5.36731, img_loss: 5.27726, d_loss: 0.0900505, d_acc.: 100.00%]]\n","Epoch 19/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.01samples/s, train=[D loss: 0.247131, acc.: 96.83%] [G total_loss: 4.53914, img_loss: 4.3624, d_loss: 0.176733, d_acc.: 96.80%], validation=[D loss: 1.38759, acc.: 50.00%] [G total_loss: 5.36159, img_loss: 5.23513, d_loss: 0.126459, d_acc.: 100.00%]]\n","Epoch 20/100: 100%|██████████| 8000/8000 [03:32<00:00, 42.18samples/s, train=[D loss: 0.201449, acc.: 99.32%] [G total_loss: 4.47418, img_loss: 4.30462, d_loss: 0.169562, d_acc.: 98.02%], validation=[D loss: 1.571, acc.: 50.00%] [G total_loss: 4.4513, img_loss: 4.31798, d_loss: 0.13332, d_acc.: 100.00%]]\n","Epoch 21/100: 100%|██████████| 8000/8000 [03:30<00:00, 43.34samples/s, train=[D loss: 0.249246, acc.: 97.08%] [G total_loss: 4.36061, img_loss: 4.22572, d_loss: 0.134892, d_acc.: 99.19%], validation=[D loss: 1.22328, acc.: 50.00%] [G total_loss: 5.22127, img_loss: 5.0397, d_loss: 0.181564, d_acc.: 100.00%]]\n","Epoch 22/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.55samples/s, train=[D loss: 0.199903, acc.: 99.46%] [G total_loss: 4.26608, img_loss: 4.14745, d_loss: 0.118634, d_acc.: 98.88%], validation=[D loss: 1.02552, acc.: 50.00%] [G total_loss: 6.10154, img_loss: 5.87055, d_loss: 0.230988, d_acc.: 100.00%]]\n","Epoch 23/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.64samples/s, train=[D loss: 0.202366, acc.: 99.28%] [G total_loss: 4.23762, img_loss: 4.10552, d_loss: 0.132106, d_acc.: 97.71%], validation=[D loss: 1.93262, acc.: 50.00%] [G total_loss: 4.86164, img_loss: 4.77284, d_loss: 0.088797, d_acc.: 100.00%]]\n","Epoch 24/100: 100%|██████████| 8000/8000 [03:30<00:00, 42.25samples/s, train=[D loss: 0.263517, acc.: 96.69%] [G total_loss: 4.15581, img_loss: 4.01477, d_loss: 0.141044, d_acc.: 98.61%], validation=[D loss: 1.17791, acc.: 50.00%] [G total_loss: 4.57366, img_loss: 4.38034, d_loss: 0.19332, d_acc.: 100.00%]]\n","Epoch 25/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.34samples/s, train=[D loss: 0.235592, acc.: 97.63%] [G total_loss: 4.088, img_loss: 3.96988, d_loss: 0.118126, d_acc.: 98.66%], validation=[D loss: 1.0421, acc.: 50.25%] [G total_loss: 4.42598, img_loss: 4.18398, d_loss: 0.242007, d_acc.: 99.00%]]\n","Epoch 26/100: 100%|██████████| 8000/8000 [03:29<00:00, 40.89samples/s, train=[D loss: 0.209791, acc.: 99.12%] [G total_loss: 4.03115, img_loss: 3.92672, d_loss: 0.104428, d_acc.: 98.90%], validation=[D loss: 1.32307, acc.: 49.75%] [G total_loss: 5.17177, img_loss: 4.99928, d_loss: 0.17249, d_acc.: 100.00%]]\n","Epoch 27/100: 100%|██████████| 8000/8000 [03:30<00:00, 42.04samples/s, train=[D loss: 0.205464, acc.: 99.14%] [G total_loss: 3.97951, img_loss: 3.8836, d_loss: 0.0959106, d_acc.: 99.26%], validation=[D loss: 1.04185, acc.: 50.00%] [G total_loss: 4.33184, img_loss: 4.11211, d_loss: 0.219733, d_acc.: 100.00%]]\n","Epoch 28/100: 100%|██████████| 8000/8000 [03:30<00:00, 42.47samples/s, train=[D loss: 0.231782, acc.: 98.22%] [G total_loss: 3.95844, img_loss: 3.83195, d_loss: 0.126493, d_acc.: 98.22%], validation=[D loss: 0.728563, acc.: 54.47%] [G total_loss: 5.14953, img_loss: 3.85496, d_loss: 1.29457, d_acc.: 0.50%]]\n","Epoch 29/100: 100%|██████████| 8000/8000 [03:27<00:00, 41.62samples/s, train=[D loss: 0.281196, acc.: 96.81%] [G total_loss: 3.98492, img_loss: 3.81044, d_loss: 0.174484, d_acc.: 98.22%], validation=[D loss: 1.9962, acc.: 49.80%] [G total_loss: 7.91196, img_loss: 4.38508, d_loss: 3.52689, d_acc.: 10.95%]]\n","Epoch 30/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.96samples/s, train=[D loss: 0.236829, acc.: 98.86%] [G total_loss: 3.96942, img_loss: 3.77871, d_loss: 0.190706, d_acc.: 97.17%], validation=[D loss: 1.88015, acc.: 49.95%] [G total_loss: 6.00208, img_loss: 3.94251, d_loss: 2.05957, d_acc.: 0.40%]]\n","Epoch 31/100: 100%|██████████| 8000/8000 [03:29<00:00, 43.36samples/s, train=[D loss: 0.221622, acc.: 98.83%] [G total_loss: 3.85185, img_loss: 3.73164, d_loss: 0.120204, d_acc.: 99.35%], validation=[D loss: 1.01656, acc.: 46.52%] [G total_loss: 5.75375, img_loss: 4.80581, d_loss: 0.947939, d_acc.: 43.75%]]\n","Epoch 32/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.14samples/s, train=[D loss: 0.207056, acc.: 99.24%] [G total_loss: 3.92924, img_loss: 3.81106, d_loss: 0.118174, d_acc.: 99.09%], validation=[D loss: 0.889854, acc.: 46.85%] [G total_loss: 5.36727, img_loss: 4.67396, d_loss: 0.693301, d_acc.: 45.80%]]\n","Epoch 33/100: 100%|██████████| 8000/8000 [03:29<00:00, 43.03samples/s, train=[D loss: 0.28555, acc.: 94.82%] [G total_loss: 3.83173, img_loss: 3.6493, d_loss: 0.182424, d_acc.: 96.15%], validation=[D loss: 0.819263, acc.: 47.50%] [G total_loss: 4.17964, img_loss: 3.76906, d_loss: 0.410577, d_acc.: 91.85%]]\n","Epoch 34/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.51samples/s, train=[D loss: 0.222501, acc.: 98.34%] [G total_loss: 3.63173, img_loss: 3.57064, d_loss: 0.0610869, d_acc.: 99.54%], validation=[D loss: 0.896785, acc.: 48.60%] [G total_loss: 4.55919, img_loss: 4.23752, d_loss: 0.321671, d_acc.: 99.85%]]\n","Epoch 35/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.10samples/s, train=[D loss: 0.247853, acc.: 97.34%] [G total_loss: 3.72463, img_loss: 3.57333, d_loss: 0.151302, d_acc.: 97.94%], validation=[D loss: 0.720634, acc.: 49.42%] [G total_loss: 5.09461, img_loss: 4.16945, d_loss: 0.925161, d_acc.: 5.80%]]\n","Epoch 36/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.47samples/s, train=[D loss: 0.23262, acc.: 97.62%] [G total_loss: 3.72671, img_loss: 3.59413, d_loss: 0.132589, d_acc.: 98.16%], validation=[D loss: 0.80117, acc.: 51.28%] [G total_loss: 5.89255, img_loss: 4.516, d_loss: 1.37655, d_acc.: 0.45%]]\n","Epoch 37/100: 100%|██████████| 8000/8000 [03:30<00:00, 42.36samples/s, train=[D loss: 0.212034, acc.: 98.64%] [G total_loss: 3.59729, img_loss: 3.49323, d_loss: 0.104052, d_acc.: 99.31%], validation=[D loss: 1.52167, acc.: 50.00%] [G total_loss: 6.57853, img_loss: 3.69613, d_loss: 2.8824, d_acc.: 0.00%]]\n","Epoch 38/100: 100%|██████████| 8000/8000 [03:28<00:00, 42.36samples/s, train=[D loss: 0.203223, acc.: 98.98%] [G total_loss: 3.53335, img_loss: 3.46925, d_loss: 0.0641059, d_acc.: 99.46%], validation=[D loss: 1.11796, acc.: 49.30%] [G total_loss: 5.73222, img_loss: 3.81672, d_loss: 1.91551, d_acc.: 16.25%]]\n","Epoch 39/100: 100%|██████████| 8000/8000 [03:28<00:00, 43.16samples/s, train=[D loss: 0.205472, acc.: 98.88%] [G total_loss: 3.53288, img_loss: 3.45428, d_loss: 0.0785994, d_acc.: 99.04%], validation=[D loss: 5.64068, acc.: 50.00%] [G total_loss: 3.77348, img_loss: 3.77161, d_loss: 0.00186427, d_acc.: 100.00%]]\n","Epoch 40/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.50samples/s, train=[D loss: 0.201969, acc.: 98.94%] [G total_loss: 3.54301, img_loss: 3.4494, d_loss: 0.0936113, d_acc.: 98.92%], validation=[D loss: 5.50513, acc.: 50.00%] [G total_loss: 3.57291, img_loss: 3.57041, d_loss: 0.00250009, d_acc.: 100.00%]]\n","Epoch 41/100: 100%|██████████| 8000/8000 [03:27<00:00, 40.55samples/s, train=[D loss: 0.204661, acc.: 98.90%] [G total_loss: 3.42729, img_loss: 3.37132, d_loss: 0.0559746, d_acc.: 99.96%], validation=[D loss: 5.96506, acc.: 50.00%] [G total_loss: 3.86863, img_loss: 3.86775, d_loss: 0.000882298, d_acc.: 100.00%]]\n","Epoch 42/100: 100%|██████████| 8000/8000 [03:29<00:00, 41.79samples/s, train=[D loss: 0.198667, acc.: 99.19%] [G total_loss: 3.4605, img_loss: 3.38201, d_loss: 0.0784829, d_acc.: 99.17%], validation=[D loss: 4.92792, acc.: 50.00%] [G total_loss: 3.79758, img_loss: 3.79566, d_loss: 0.00192129, d_acc.: 100.00%]]\n","Epoch 43/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.79samples/s, train=[D loss: 0.192264, acc.: 99.48%] [G total_loss: 3.45278, img_loss: 3.36429, d_loss: 0.0884907, d_acc.: 98.81%], validation=[D loss: 4.68682, acc.: 50.00%] [G total_loss: 4.30308, img_loss: 4.30068, d_loss: 0.00240244, d_acc.: 100.00%]]\n","Epoch 44/100: 100%|██████████| 8000/8000 [03:28<00:00, 41.40samples/s, train=[D loss: 0.190598, acc.: 99.43%] [G total_loss: 3.40634, img_loss: 3.33135, d_loss: 0.0749816, d_acc.: 99.72%], validation=[D loss: 6.63236, acc.: 50.00%] [G total_loss: 3.55255, img_loss: 3.55217, d_loss: 0.000379053, d_acc.: 100.00%]]\n","Epoch 45/100: 100%|██████████| 8000/8000 [03:31<00:00, 41.12samples/s, train=[D loss: 0.20726, acc.: 98.85%] [G total_loss: 3.38078, img_loss: 3.28382, d_loss: 0.0969625, d_acc.: 99.16%], validation=[D loss: 2.15475, acc.: 50.00%] [G total_loss: 3.80571, img_loss: 3.77373, d_loss: 0.0319878, d_acc.: 100.00%]]\n","Epoch 46/100: 100%|██████████| 8000/8000 [03:31<00:00, 42.62samples/s, train=[D loss: 0.201887, acc.: 99.06%] [G total_loss: 3.37651, img_loss: 3.28139, d_loss: 0.0951109, d_acc.: 98.86%], validation=[D loss: 1.27574, acc.: 49.10%] [G total_loss: 3.90944, img_loss: 3.73668, d_loss: 0.172759, d_acc.: 98.70%]]\n","Epoch 47/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.49samples/s, train=[D loss: 0.20019, acc.: 98.91%] [G total_loss: 3.3089, img_loss: 3.2285, d_loss: 0.0804037, d_acc.: 99.52%], validation=[D loss: 0.687744, acc.: 60.02%] [G total_loss: 4.44583, img_loss: 3.46003, d_loss: 0.985799, d_acc.: 20.60%]]\n","Epoch 48/100: 100%|██████████| 8000/8000 [03:28<00:00, 42.03samples/s, train=[D loss: 0.192463, acc.: 99.36%] [G total_loss: 3.28469, img_loss: 3.20252, d_loss: 0.0821714, d_acc.: 99.56%], validation=[D loss: 5.48354, acc.: 50.00%] [G total_loss: 4.30996, img_loss: 4.30902, d_loss: 0.000933558, d_acc.: 100.00%]]\n","Epoch 49/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.93samples/s, train=[D loss: 0.217566, acc.: 98.34%] [G total_loss: 3.31473, img_loss: 3.22529, d_loss: 0.089445, d_acc.: 99.19%], validation=[D loss: 3.16986, acc.: 50.00%] [G total_loss: 3.69282, img_loss: 3.68181, d_loss: 0.0110111, d_acc.: 100.00%]]\n","Epoch 50/100: 100%|██████████| 8000/8000 [03:29<00:00, 41.90samples/s, train=[D loss: 0.194283, acc.: 99.23%] [G total_loss: 3.27423, img_loss: 3.18611, d_loss: 0.0881221, d_acc.: 99.55%], validation=[D loss: 2.43481, acc.: 50.00%] [G total_loss: 3.90485, img_loss: 3.88528, d_loss: 0.0195682, d_acc.: 100.00%]]\n","Epoch 51/100: 100%|██████████| 8000/8000 [03:27<00:00, 41.81samples/s, train=[D loss: 0.185788, acc.: 99.58%] [G total_loss: 3.29381, img_loss: 3.18508, d_loss: 0.108731, d_acc.: 98.75%], validation=[D loss: 3.46691, acc.: 50.00%] [G total_loss: 3.70826, img_loss: 3.69976, d_loss: 0.00850064, d_acc.: 100.00%]]\n","Epoch 52/100: 100%|██████████| 8000/8000 [03:30<00:00, 42.42samples/s, train=[D loss: 0.196679, acc.: 99.05%] [G total_loss: 3.28581, img_loss: 3.1884, d_loss: 0.0974038, d_acc.: 98.59%], validation=[D loss: 4.11696, acc.: 50.00%] [G total_loss: 3.5554, img_loss: 3.55088, d_loss: 0.00452204, d_acc.: 100.00%]]\n","Epoch 53/100: 100%|██████████| 8000/8000 [03:32<00:00, 38.48samples/s, train=[D loss: 0.193838, acc.: 99.40%] [G total_loss: 3.19869, img_loss: 3.11084, d_loss: 0.0878448, d_acc.: 99.25%], validation=[D loss: 3.08894, acc.: 50.00%] [G total_loss: 3.67854, img_loss: 3.66956, d_loss: 0.00897941, d_acc.: 100.00%]]\n","Epoch 54/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.04samples/s, train=[D loss: 0.194144, acc.: 99.16%] [G total_loss: 3.30333, img_loss: 3.19335, d_loss: 0.109977, d_acc.: 98.04%], validation=[D loss: 3.13137, acc.: 50.00%] [G total_loss: 3.60436, img_loss: 3.59317, d_loss: 0.0111955, d_acc.: 100.00%]]\n","Epoch 55/100: 100%|██████████| 8000/8000 [03:30<00:00, 42.93samples/s, train=[D loss: 0.190526, acc.: 99.38%] [G total_loss: 3.19653, img_loss: 3.10139, d_loss: 0.0951448, d_acc.: 99.12%], validation=[D loss: 5.19967, acc.: 50.00%] [G total_loss: 3.56324, img_loss: 3.56181, d_loss: 0.00142549, d_acc.: 100.00%]]\n","Epoch 56/100: 100%|██████████| 8000/8000 [03:30<00:00, 42.29samples/s, train=[D loss: 0.192384, acc.: 99.34%] [G total_loss: 3.1303, img_loss: 3.0493, d_loss: 0.0810017, d_acc.: 99.55%], validation=[D loss: 3.88191, acc.: 50.00%] [G total_loss: 3.323, img_loss: 3.31845, d_loss: 0.00454665, d_acc.: 100.00%]]\n","Epoch 57/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.05samples/s, train=[D loss: 0.19536, acc.: 99.13%] [G total_loss: 3.14843, img_loss: 3.06028, d_loss: 0.0881501, d_acc.: 99.21%], validation=[D loss: 3.57971, acc.: 50.00%] [G total_loss: 3.25676, img_loss: 3.25018, d_loss: 0.00657816, d_acc.: 100.00%]]\n","Epoch 58/100: 100%|██████████| 8000/8000 [03:27<00:00, 42.37samples/s, train=[D loss: 0.189305, acc.: 99.53%] [G total_loss: 3.13728, img_loss: 3.04067, d_loss: 0.0966108, d_acc.: 99.30%], validation=[D loss: 3.59863, acc.: 50.00%] [G total_loss: 3.33234, img_loss: 3.32868, d_loss: 0.00366257, d_acc.: 100.00%]]\n","Epoch 59/100: 100%|██████████| 8000/8000 [03:26<00:00, 43.46samples/s, train=[D loss: 0.195959, acc.: 99.22%] [G total_loss: 3.15112, img_loss: 3.04924, d_loss: 0.101882, d_acc.: 98.62%], validation=[D loss: 4.87601, acc.: 50.00%] [G total_loss: 3.31908, img_loss: 3.31761, d_loss: 0.00146986, d_acc.: 100.00%]]\n","Epoch 60/100: 100%|██████████| 8000/8000 [03:25<00:00, 42.38samples/s, train=[D loss: 0.19533, acc.: 99.11%] [G total_loss: 3.0801, img_loss: 2.99607, d_loss: 0.0840367, d_acc.: 99.95%], validation=[D loss: 6.88684, acc.: 50.00%] [G total_loss: 3.37088, img_loss: 3.37083, d_loss: 5.31213e-05, d_acc.: 100.00%]]\n","Epoch 61/100: 100%|██████████| 8000/8000 [03:25<00:00, 43.16samples/s, train=[D loss: 0.189327, acc.: 99.32%] [G total_loss: 3.10597, img_loss: 3.01206, d_loss: 0.0939027, d_acc.: 98.61%], validation=[D loss: 4.96191, acc.: 50.00%] [G total_loss: 3.97418, img_loss: 3.973, d_loss: 0.00118455, d_acc.: 100.00%]]\n","Epoch 62/100: 100%|██████████| 8000/8000 [03:27<00:00, 42.53samples/s, train=[D loss: 0.187539, acc.: 99.56%] [G total_loss: 3.05185, img_loss: 2.96242, d_loss: 0.0894261, d_acc.: 99.52%], validation=[D loss: 4.4005, acc.: 50.00%] [G total_loss: 3.60334, img_loss: 3.60008, d_loss: 0.00325307, d_acc.: 100.00%]]\n","Epoch 63/100: 100%|██████████| 8000/8000 [03:28<00:00, 41.57samples/s, train=[D loss: 0.190229, acc.: 99.46%] [G total_loss: 3.08241, img_loss: 2.97869, d_loss: 0.10372, d_acc.: 98.80%], validation=[D loss: 6.37762, acc.: 50.00%] [G total_loss: 3.37185, img_loss: 3.3714, d_loss: 0.000444745, d_acc.: 100.00%]]\n","Epoch 64/100: 100%|██████████| 8000/8000 [03:28<00:00, 42.43samples/s, train=[D loss: 0.195313, acc.: 99.12%] [G total_loss: 3.05063, img_loss: 2.96539, d_loss: 0.0852338, d_acc.: 99.31%], validation=[D loss: 6.12129, acc.: 50.00%] [G total_loss: 3.47212, img_loss: 3.47116, d_loss: 0.000961209, d_acc.: 100.00%]]\n","Epoch 65/100: 100%|██████████| 8000/8000 [03:32<00:00, 41.67samples/s, train=[D loss: 0.185453, acc.: 99.35%] [G total_loss: 3.00748, img_loss: 2.92937, d_loss: 0.0781175, d_acc.: 99.78%], validation=[D loss: 5.54181, acc.: 50.00%] [G total_loss: 3.39177, img_loss: 3.38988, d_loss: 0.0018884, d_acc.: 100.00%]]\n","Epoch 66/100: 100%|██████████| 8000/8000 [03:32<00:00, 41.94samples/s, train=[D loss: 0.186275, acc.: 99.51%] [G total_loss: 2.9944, img_loss: 2.91489, d_loss: 0.0795135, d_acc.: 99.45%], validation=[D loss: 4.56881, acc.: 50.00%] [G total_loss: 3.23522, img_loss: 3.23142, d_loss: 0.0038043, d_acc.: 100.00%]]\n","Epoch 67/100: 100%|██████████| 8000/8000 [03:37<00:00, 41.05samples/s, train=[D loss: 0.190268, acc.: 99.25%] [G total_loss: 2.98027, img_loss: 2.88976, d_loss: 0.0905063, d_acc.: 99.59%], validation=[D loss: 4.39798, acc.: 50.00%] [G total_loss: 3.2184, img_loss: 3.21416, d_loss: 0.00423571, d_acc.: 100.00%]]\n","Epoch 68/100: 100%|██████████| 8000/8000 [03:38<00:00, 41.24samples/s, train=[D loss: 0.190516, acc.: 99.29%] [G total_loss: 2.97631, img_loss: 2.88073, d_loss: 0.095575, d_acc.: 99.14%], validation=[D loss: 1.90876, acc.: 50.00%] [G total_loss: 3.34714, img_loss: 3.29397, d_loss: 0.0531713, d_acc.: 100.00%]]\n","Epoch 69/100: 100%|██████████| 8000/8000 [03:37<00:00, 41.12samples/s, train=[D loss: 0.191328, acc.: 99.27%] [G total_loss: 2.95549, img_loss: 2.86902, d_loss: 0.0864751, d_acc.: 99.10%], validation=[D loss: 4.65374, acc.: 50.00%] [G total_loss: 3.33047, img_loss: 3.32802, d_loss: 0.00244452, d_acc.: 100.00%]]\n","Epoch 70/100: 100%|██████████| 8000/8000 [03:33<00:00, 41.62samples/s, train=[D loss: 0.186315, acc.: 99.54%] [G total_loss: 2.92193, img_loss: 2.84206, d_loss: 0.0798697, d_acc.: 99.50%], validation=[D loss: 5.12015, acc.: 50.00%] [G total_loss: 3.49773, img_loss: 3.49598, d_loss: 0.00175251, d_acc.: 100.00%]]\n","Epoch 71/100: 100%|██████████| 8000/8000 [03:32<00:00, 41.04samples/s, train=[D loss: 0.192602, acc.: 99.37%] [G total_loss: 2.93209, img_loss: 2.83294, d_loss: 0.0991458, d_acc.: 98.71%], validation=[D loss: 2.78553, acc.: 50.00%] [G total_loss: 4.13321, img_loss: 4.11776, d_loss: 0.0154442, d_acc.: 100.00%]]\n","Epoch 72/100: 100%|██████████| 8000/8000 [03:33<00:00, 41.82samples/s, train=[D loss: 0.181215, acc.: 99.84%] [G total_loss: 2.89669, img_loss: 2.81714, d_loss: 0.0795481, d_acc.: 99.65%], validation=[D loss: 1.78491, acc.: 49.88%] [G total_loss: 3.34194, img_loss: 3.27666, d_loss: 0.0652788, d_acc.: 100.00%]]\n","Epoch 73/100: 100%|██████████| 8000/8000 [03:31<00:00, 42.11samples/s, train=[D loss: 0.189956, acc.: 99.37%] [G total_loss: 2.89356, img_loss: 2.8187, d_loss: 0.074858, d_acc.: 99.79%], validation=[D loss: 6.54282, acc.: 50.00%] [G total_loss: 3.32611, img_loss: 3.32592, d_loss: 0.000191886, d_acc.: 100.00%]]\n","Epoch 74/100: 100%|██████████| 8000/8000 [03:34<00:00, 41.37samples/s, train=[D loss: 0.182781, acc.: 99.78%] [G total_loss: 2.8541, img_loss: 2.78565, d_loss: 0.0684528, d_acc.: 100.00%], validation=[D loss: 6.65858, acc.: 50.00%] [G total_loss: 3.27423, img_loss: 3.27409, d_loss: 0.000142984, d_acc.: 100.00%]]\n","Epoch 75/100: 100%|██████████| 8000/8000 [03:31<00:00, 39.67samples/s, train=[D loss: 0.191858, acc.: 99.24%] [G total_loss: 2.91443, img_loss: 2.83531, d_loss: 0.0791292, d_acc.: 99.60%], validation=[D loss: 7.2143, acc.: 50.00%] [G total_loss: 3.05369, img_loss: 3.05367, d_loss: 2.51338e-05, d_acc.: 100.00%]]\n","Epoch 76/100: 100%|██████████| 8000/8000 [03:31<00:00, 42.29samples/s, train=[D loss: 0.18518, acc.: 99.66%] [G total_loss: 2.88701, img_loss: 2.80309, d_loss: 0.0839226, d_acc.: 99.31%], validation=[D loss: 6.0115, acc.: 50.00%] [G total_loss: 3.2891, img_loss: 3.28868, d_loss: 0.000413138, d_acc.: 100.00%]]\n","Epoch 77/100: 100%|██████████| 8000/8000 [03:31<00:00, 41.87samples/s, train=[D loss: 0.187849, acc.: 99.48%] [G total_loss: 2.84481, img_loss: 2.75739, d_loss: 0.0874185, d_acc.: 99.59%], validation=[D loss: 6.25179, acc.: 50.00%] [G total_loss: 3.17272, img_loss: 3.17224, d_loss: 0.000475361, d_acc.: 100.00%]]\n","Epoch 78/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.55samples/s, train=[D loss: 0.186092, acc.: 99.66%] [G total_loss: 2.82883, img_loss: 2.74354, d_loss: 0.0852909, d_acc.: 99.49%], validation=[D loss: 6.0262, acc.: 50.00%] [G total_loss: 3.76619, img_loss: 3.76556, d_loss: 0.000624748, d_acc.: 100.00%]]\n","Epoch 79/100: 100%|██████████| 8000/8000 [03:29<00:00, 41.88samples/s, train=[D loss: 0.185493, acc.: 99.64%] [G total_loss: 2.82812, img_loss: 2.73765, d_loss: 0.0904683, d_acc.: 99.49%], validation=[D loss: 5.47034, acc.: 50.00%] [G total_loss: 3.23759, img_loss: 3.23447, d_loss: 0.00311844, d_acc.: 100.00%]]\n","Epoch 80/100: 100%|██████████| 8000/8000 [03:31<00:00, 41.40samples/s, train=[D loss: 0.190256, acc.: 99.39%] [G total_loss: 2.80823, img_loss: 2.71532, d_loss: 0.0929144, d_acc.: 99.30%], validation=[D loss: 7.32719, acc.: 50.00%] [G total_loss: 3.16966, img_loss: 3.16964, d_loss: 1.85845e-05, d_acc.: 100.00%]]\n","Epoch 81/100: 100%|██████████| 8000/8000 [03:32<00:00, 40.98samples/s, train=[D loss: 0.183537, acc.: 99.80%] [G total_loss: 2.78154, img_loss: 2.70352, d_loss: 0.0780207, d_acc.: 99.86%], validation=[D loss: 6.79309, acc.: 50.00%] [G total_loss: 3.24356, img_loss: 3.24344, d_loss: 0.000127685, d_acc.: 100.00%]]\n","Epoch 82/100: 100%|██████████| 8000/8000 [03:33<00:00, 40.86samples/s, train=[D loss: 0.181762, acc.: 99.94%] [G total_loss: 2.7837, img_loss: 2.6865, d_loss: 0.0972062, d_acc.: 99.16%], validation=[D loss: 3.59758, acc.: 50.00%] [G total_loss: 3.20278, img_loss: 3.19119, d_loss: 0.0115875, d_acc.: 100.00%]]\n","Epoch 83/100: 100%|██████████| 8000/8000 [03:35<00:00, 41.08samples/s, train=[D loss: 0.188375, acc.: 99.64%] [G total_loss: 2.76889, img_loss: 2.68786, d_loss: 0.0810293, d_acc.: 99.59%], validation=[D loss: 5.80934, acc.: 50.00%] [G total_loss: 3.09737, img_loss: 3.09591, d_loss: 0.00145527, d_acc.: 100.00%]]\n","Epoch 84/100: 100%|██████████| 8000/8000 [03:31<00:00, 42.48samples/s, train=[D loss: 0.183207, acc.: 99.64%] [G total_loss: 2.76315, img_loss: 2.67936, d_loss: 0.0837919, d_acc.: 99.12%], validation=[D loss: 5.46512, acc.: 50.00%] [G total_loss: 3.44918, img_loss: 3.44778, d_loss: 0.0013971, d_acc.: 100.00%]]\n","Epoch 85/100: 100%|██████████| 8000/8000 [03:29<00:00, 42.83samples/s, train=[D loss: 0.185674, acc.: 99.51%] [G total_loss: 2.75449, img_loss: 2.66015, d_loss: 0.0943355, d_acc.: 99.06%], validation=[D loss: 6.57004, acc.: 50.00%] [G total_loss: 3.2534, img_loss: 3.2531, d_loss: 0.000302967, d_acc.: 100.00%]]\n","Epoch 86/100: 100%|██████████| 8000/8000 [03:31<00:00, 41.05samples/s, train=[D loss: 0.180568, acc.: 99.94%] [G total_loss: 2.72739, img_loss: 2.63015, d_loss: 0.0972386, d_acc.: 99.20%], validation=[D loss: 5.62912, acc.: 50.00%] [G total_loss: 3.28234, img_loss: 3.28059, d_loss: 0.00174671, d_acc.: 100.00%]]\n","Epoch 87/100: 100%|██████████| 8000/8000 [03:30<00:00, 41.89samples/s, train=[D loss: 0.180674, acc.: 99.91%] [G total_loss: 2.67567, img_loss: 2.60577, d_loss: 0.0698933, d_acc.: 99.95%], validation=[D loss: 1.66139, acc.: 50.00%] [G total_loss: 3.36537, img_loss: 3.23582, d_loss: 0.129554, d_acc.: 99.70%]]\n","Epoch 88/100: 100%|██████████| 8000/8000 [03:35<00:00, 40.72samples/s, train=[D loss: 0.190876, acc.: 99.32%] [G total_loss: 2.74933, img_loss: 2.64731, d_loss: 0.102019, d_acc.: 98.98%], validation=[D loss: 2.68414, acc.: 50.00%] [G total_loss: 3.25968, img_loss: 3.23927, d_loss: 0.0204066, d_acc.: 100.00%]]\n","Epoch 89/100: 100%|██████████| 8000/8000 [03:39<00:00, 40.60samples/s, train=[D loss: 0.181809, acc.: 99.70%] [G total_loss: 2.69768, img_loss: 2.6182, d_loss: 0.0794847, d_acc.: 99.58%], validation=[D loss: 1.61297, acc.: 49.93%] [G total_loss: 3.23604, img_loss: 3.13142, d_loss: 0.10462, d_acc.: 99.50%]]\n","Epoch 90/100: 100%|██████████| 8000/8000 [03:37<00:00, 40.09samples/s, train=[D loss: 0.183077, acc.: 99.69%] [G total_loss: 2.68479, img_loss: 2.61177, d_loss: 0.0730194, d_acc.: 99.45%], validation=[D loss: 1.54287, acc.: 54.65%] [G total_loss: 6.61929, img_loss: 3.19281, d_loss: 3.42648, d_acc.: 10.20%]]\n","Epoch 91/100: 100%|██████████| 8000/8000 [03:36<00:00, 41.00samples/s, train=[D loss: 0.181323, acc.: 99.70%] [G total_loss: 2.66093, img_loss: 2.59412, d_loss: 0.0668024, d_acc.: 99.60%], validation=[D loss: 3.1503, acc.: 50.08%] [G total_loss: 10.0083, img_loss: 3.12971, d_loss: 6.87859, d_acc.: 0.00%]]\n","Epoch 92/100: 100%|██████████| 8000/8000 [03:34<00:00, 40.56samples/s, train=[D loss: 0.18449, acc.: 99.64%] [G total_loss: 2.65384, img_loss: 2.58369, d_loss: 0.07015, d_acc.: 99.75%], validation=[D loss: 6.20287, acc.: 50.00%] [G total_loss: 15.8039, img_loss: 3.0917, d_loss: 12.7122, d_acc.: 0.00%]]\n","Epoch 93/100: 100%|██████████| 8000/8000 [03:36<00:00, 40.59samples/s, train=[D loss: 0.182906, acc.: 99.88%] [G total_loss: 2.63155, img_loss: 2.55272, d_loss: 0.0788326, d_acc.: 99.58%], validation=[D loss: 1.90554, acc.: 50.62%] [G total_loss: 7.26762, img_loss: 3.09345, d_loss: 4.17417, d_acc.: 0.35%]]\n","Epoch 94/100: 100%|██████████| 8000/8000 [03:32<00:00, 41.69samples/s, train=[D loss: 0.182452, acc.: 99.71%] [G total_loss: 2.61632, img_loss: 2.54506, d_loss: 0.0712584, d_acc.: 99.54%], validation=[D loss: 1.13337, acc.: 49.88%] [G total_loss: 4.43323, img_loss: 3.25511, d_loss: 1.17812, d_acc.: 36.15%]]\n","Epoch 95/100: 100%|██████████| 8000/8000 [03:30<00:00, 42.60samples/s, train=[D loss: 0.185176, acc.: 99.65%] [G total_loss: 2.67466, img_loss: 2.57896, d_loss: 0.0956942, d_acc.: 99.06%], validation=[D loss: 1.02412, acc.: 50.60%] [G total_loss: 3.63597, img_loss: 3.08555, d_loss: 0.550416, d_acc.: 77.70%]]\n","Epoch 96/100: 100%|██████████| 8000/8000 [03:31<00:00, 41.41samples/s, train=[D loss: 0.18448, acc.: 99.67%] [G total_loss: 2.63665, img_loss: 2.55082, d_loss: 0.0858394, d_acc.: 99.12%], validation=[D loss: 2.90851, acc.: 49.95%] [G total_loss: 3.45973, img_loss: 3.44149, d_loss: 0.0182461, d_acc.: 99.95%]]\n","Epoch 97/100: 100%|██████████| 8000/8000 [03:34<00:00, 41.58samples/s, train=[D loss: 0.188986, acc.: 99.57%] [G total_loss: 2.66179, img_loss: 2.56026, d_loss: 0.101533, d_acc.: 99.16%], validation=[D loss: 2.32094, acc.: 49.80%] [G total_loss: 3.31098, img_loss: 3.13876, d_loss: 0.17222, d_acc.: 91.20%]]\n","Epoch 98/100: 100%|██████████| 8000/8000 [03:31<00:00, 42.35samples/s, train=[D loss: 0.18401, acc.: 99.83%] [G total_loss: 2.68136, img_loss: 2.55686, d_loss: 0.124499, d_acc.: 98.15%], validation=[D loss: 2.51932, acc.: 50.82%] [G total_loss: 3.46391, img_loss: 3.31187, d_loss: 0.152045, d_acc.: 95.40%]]\n","Epoch 99/100: 100%|██████████| 8000/8000 [03:32<00:00, 41.83samples/s, train=[D loss: 0.184022, acc.: 99.63%] [G total_loss: 2.61327, img_loss: 2.52986, d_loss: 0.0834086, d_acc.: 99.60%], validation=[D loss: 3.13048, acc.: 50.00%] [G total_loss: 3.07918, img_loss: 3.06286, d_loss: 0.0163192, d_acc.: 100.00%]]\n","Epoch 100/100: 100%|██████████| 8000/8000 [03:31<00:00, 42.04samples/s, train=[D loss: 0.178141, acc.: 99.86%] [G total_loss: 2.61244, img_loss: 2.50075, d_loss: 0.111695, d_acc.: 98.95%], validation=[D loss: 2.54594, acc.: 50.00%] [G total_loss: 3.25711, img_loss: 3.21853, d_loss: 0.0385798, d_acc.: 100.00%]]\n","/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:883: UserWarning: Layer bidirectional_1 was passed non-serializable keyword arguments: {'mask': <tf.Tensor 'lambda_5/Squeeze:0' shape=(?, ?) dtype=float32>}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KGCNo7HN9yDy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"83da0098-d88e-443a-988e-304f316766b5","executionInfo":{"status":"error","timestamp":1578935580332,"user_tz":-480,"elapsed":9092504,"user":{"displayName":"代安語","photoUrl":"","userId":"02683702717166278139"}}},"source":["from builder import *\n","from tqdm import tqdm\n","from keras.callbacks import BaseLogger, History, CallbackList, ModelCheckpoint\n","from scipy.ndimage import gaussian_filter\n","from scipy.stats import truncnorm\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","# def blur_image(image):\n","#     blur_param = np.random.random()\n","#     noise_param = np.random.random() * blur_param\n","#     image = image + image * truncnorm.rvs(-2, 2, scale=noise_param * 0.5, size=image.shape)\n","#     image = gaussian_filter(image, blur_param * 5.0)\n","#     return image\n","\n","\n","def transform_theta(points, theta):\n","    theta = theta * (np.pi / 180)\n","    x = points[:, [0]] - 0.5\n","    y = -(points[:, [1]] - 0.5)\n","    x1 = x * np.cos(theta) - y * np.sin(theta) + 0.5\n","    y1 = -x * np.sin(theta) - y * np.cos(theta) + 0.5\n","    x = points[:, [2]] - 0.5\n","    y = -(points[:, [3]] - 0.5)\n","    x2 = x * np.cos(theta) - y * np.sin(theta) + 0.5\n","    y2 = -x * np.sin(theta) - y * np.cos(theta) + 0.5\n","    return np.concatenate([x1, y1, x2, y2], axis=1)\n","\n","\n","key = 'training_16_old'\n","MU_training = MU[key]\n","MU_norm_training = MU_norm[key]\n","PHI_meas_training = PHI_meas[key]\n","MUa_training = MUa[key]\n","MUsp_training = MUsp[key]\n","lr = 0.0002\n","beta_1 = 0.5\n","# clip_value = 0.01\n","# optimizer = Adam(lr=lr, beta_1=beta_1)\n","# optimizer = RMSprop(lr=lr)\n","generator, gen_names = primary_net()\n","print('Generator model summary:')\n","generator.summary()\n","discriminator, dis_names = secondary_net()\n","discriminator.name = 'discriminator'\n","metric_groups = [['mae', 'mse', 'mape', 'msle', 'logcosh', 'cosine'], [custom_binary_accuracy]]\n","# dis_losses = ['binary_crossentropy', 'mse', 'msle']\n","# dis_lw = [1, 20, 0.01]\n","# discriminator.compile(loss=dis_losses, loss_weights=dis_lw, optimizer=optimizer,\n","#                       metrics={dis_names[0]: metric_groups[1], dis_names[1]: metric_groups[0],\n","#                                dis_names[2]: metric_groups[0]})\n","dis_losses = ['binary_crossentropy']\n","dis_lw = [1]\n","discriminator.compile(loss=dis_losses, optimizer=Adam(lr=lr, beta_1=beta_1), metrics=metric_groups[1])\n","print('Discriminator model summary:')\n","discriminator.summary()\n","discriminator.trainable = False\n","# inputs = Input((None,)+PHI_meas_training.shape[2:])\n","# outputs = generator(inputs)\n","outputs = generator.outputs\n","if len(dis_names) == 1:\n","    outputs += [discriminator(outputs[:2])]\n","else:\n","    outputs += discriminator(outputs[:2])\n","gan = Model(inputs=generator.inputs, outputs=outputs)\n","losses = ['mse', 'mse', 'mse', 'mse', 'mse', 'mse'] + dis_losses\n","loss_weights = [0, 0, 5, 5, 1e4, 1] + dis_lw\n","metrics = {}\n","for name in gen_names:\n","    metrics[name] = metric_groups[0]\n","if len(dis_names) == 1:\n","    metrics[discriminator.name] = metric_groups[1]\n","else:\n","    metrics[discriminator.name] = metric_groups[1] + metric_groups[0]\n","dis_metrics_len = len(metrics[discriminator.name])\n","# gan_d_loss_idx_offset = 7 + len(gen_names) * len(metric_groups[0])\n","gan.compile(loss=losses, loss_weights=loss_weights, optimizer=Adam(lr=lr, beta_1=beta_1), metrics=metrics)\n","print('Generative adversarial network model summary:')\n","gan.summary()\n","dataset = datasets[key]\n","val_size = dataset.val_size\n","data_size = dataset.data_size\n","train_size = dataset.train_size\n","count_label = dataset.count_label\n","pos_data = dataset.pos_data\n","inc_areas = dataset.inc_areas\n","N_count = dataset.N_count\n","choice = np.zeros(data_size, dtype='uint8')\n","choice[np.random.choice(data_size, val_size, replace=False)] = 1\n","# choice = dataset.data_label\n","MU_training_train = MU_training[choice == 0]\n","MU_training_val = MU_training[choice == 1]\n","MU_norm_training_train = MU_norm_training[choice == 0]\n","MU_norm_training_val = MU_norm_training[choice == 1]\n","PHI_meas_training_train = PHI_meas_training[choice == 0]\n","PHI_meas_train_raw = PHI_meas_raw[key][choice == 0]\n","PHI_meas_std = np.std(PHI_meas_train_raw, axis=1)\n","PHI_meas_training_val = PHI_meas_training[choice == 1]\n","freq_training_train = freq[key][choice == 0]\n","freq_training_val = freq[key][choice == 1]\n","d_training_train = d[key][choice == 0]\n","d_training_val = d[key][choice == 1]\n","seq_len_train = seq_len[key][choice == 0]\n","seq_len_val = seq_len[key][choice == 1]\n","MUa_train = MUa_training[choice == 0]\n","MUa_val = MUa_training[choice == 1]\n","MUsp_train = MUsp_training[choice == 0]\n","MUsp_val = MUsp_training[choice == 1]\n","count_label_train = count_label[choice == 0]\n","count_label_val = count_label[choice == 1]\n","pos_data_train = pos_data[choice == 0]\n","pos_data_val = pos_data[choice == 1]\n","inc_areas_train = inc_areas[choice == 0]\n","inc_areas_val = inc_areas[choice == 1]\n","N_count_train = np.zeros_like(N_count)\n","N_count_val = np.zeros_like(N_count)\n","n = 0\n","for i in range(len(N_count)):\n","    ni = N_count[i]\n","    N_count_train[i] = np.where(choice[n:(n + ni)] == 0)[0].size\n","    N_count_val[i] = ni - N_count_train[i]\n","    n += ni\n","idx = np.lexsort((count_label_train, seq_len_train))[::-1]\n","index_array_dis = idx\n","index_array_gan = np.copy(idx)\n","ia = np.arange(train_size)\n","nsc_u, idx = np.unique((count_label_train, seq_len_train), axis=1, return_inverse=True)\n","nsc_u = nsc_u[:, ::-1]\n","idx = len(nsc_u) - 1 - idx\n","idx = idx[index_array_dis]\n","ns_u, idx2 = np.unique(seq_len_train, return_inverse=True)\n","idx2 = idx2[index_array_dis]\n","# choice = data_cat\n","batch_size = 32\n","prob_param = 20.0\n","prob_param2 = 1.0\n","# label_softness = 0.1\n","# metrics_eval_n = 50\n","# metrics_eval_step = 20\n","hard_valid = np.ones(val_size)\n","hard_fake = np.zeros(val_size)\n","# noise_max = 0.1\n","# noise_add_max = 1e-3\n","datagen = ImageDataGenerator(rotation_range=360, horizontal_flip=True, vertical_flip=True)\n","\n","\n","# soft_label = False\n","# augment = True\n","# min_img_loss_avg = np.inf\n","# min_dis_loss_avg = np.inf\n","# img_loss_baseline_factor = 1.1\n","# img_loss_threshold = 1.2\n","# img_loss_threshold2 = 0.6\n","# prob_augment = 0.5\n","# gan_d_acc = [0.5, 0.5]\n","# init_train = 100\n","apply_noise = False\n","print(gan.metrics_names)\n","print(discriminator.metrics_names)\n","# model_name = input('Enter model name: ')\n","model_name = 'model46log'\n","checkpoint = ModelCheckpoint(model_name + '_{epoch:02d}.h5', period=10)\n","checkpoint.set_model(gan)\n","checkpoint_gen = ModelCheckpoint(model_name + '_gen_{epoch:02d}.h5', period=10)\n","checkpoint_gen.set_model(generator)\n","checkpoint_dis = ModelCheckpoint(model_name + '_dis_{epoch:02d}.h5', period=10)\n","checkpoint_dis.set_model(discriminator)\n","\n","\n","def run_epoch(start, end=None):\n","    global PHI_meas_training_train\n","\n","    if end is None:\n","        end = start\n","        start = 0\n","\n","    history = History()\n","    logger = BaseLogger(stateful_metrics=['discriminator_' + s for s in discriminator.stateful_metric_names] +\n","                                         ['gan_' + s for s in gan.stateful_metric_names])\n","    time_history = TimeHistory()\n","    callbacks = [logger, time_history, history, checkpoint, checkpoint_gen, checkpoint_dis]\n","    out_labels = ['discriminator_' + s for s in discriminator.metrics_names] +\\\n","                 ['discriminator_real_' + s for s in discriminator.metrics_names] +\\\n","                 ['discriminator_fake_' + s for s in discriminator.metrics_names] +\\\n","                 ['gan_' + s for s in gan.metrics_names]\n","    dis_metrics_names_len = len(discriminator.metrics_names)\n","    out_labels[dis_metrics_names_len*3 + 8] = 'gan_discriminator_pos_loss'\n","    out_labels[dis_metrics_names_len*3 + 9] = 'gan_discriminator_area_loss'\n","    callback_metrics = copy.copy(out_labels) + ['val_' + n for n in out_labels]\n","    callbacks = CallbackList(callbacks)\n","    # callbacks = [TimeHistory(), EarlyStopping(monitor='loss', min_delta=0.1, patience=100,\n","    #                                           restore_best_weights=True, verbose=1)]\n","    # early_stop = EarlyStopping(patience=200, verbose=1)\n","    callbacks.set_params({\n","        'batch_size': batch_size,\n","        'epochs': end,\n","        'steps': None,\n","        'samples': train_size,\n","        'verbose': 2,\n","        'do_validation': True,\n","        'metrics': callback_metrics,\n","    })\n","    callbacks.on_train_begin()\n","    # n = N_count_train[0]\n","    # np.random.shuffle(index_array_dis[:n])\n","    # np.random.shuffle(index_array_gan[:n])\n","    # for i in range(1, len(N_count_train) - 1):\n","    #     ni = N_count_train[i]\n","    #     np.random.shuffle(index_array_dis[n:(n + ni)])\n","    #     np.random.shuffle(index_array_gan[n:(n + ni)])\n","    #     n += ni\n","    # np.random.shuffle(index_array_dis[n:])\n","    # np.random.shuffle(index_array_gan[n:])\n","    for i in range(len(nsc_u)):\n","        np.random.shuffle(index_array_dis[idx == i])\n","        np.random.shuffle(index_array_gan[idx == i])\n","    for epoch in range(start, end):\n","        for m in discriminator.stateful_metric_functions:\n","            m.reset_states()\n","        for m in gan.stateful_metric_functions:\n","            m.reset_states()\n","        callbacks.on_epoch_begin(epoch)\n","        epoch_logs = {}\n","        progress_bar = None\n","        for u in ns_u:\n","            np.random.shuffle(ia[ns_u[idx2] == u])\n","        if apply_noise:\n","            PHI_meas_training_train = PHI_meas_training[choice == 0]\n","            noise_flag = np.random.random((train_size, 1)) >= 0.5\n","            meas_noise = np.random.random((train_size, 1)) * noise_max * noise_flag\n","            meas_add_noise = np.random.random((train_size, 1)) * noise_add_max * noise_flag\n","            noise = np.apply_along_axis(lambda a: (np.random.normal(scale=1 / np.sqrt(2),\n","                                                                    size=PHI_meas_train_raw.shape[1:]) +\n","                                                   np.random.normal(scale=1 / np.sqrt(2),\n","                                                                    size=PHI_meas_train_raw.shape[1:]) * 1j) * a, 1,\n","                                        meas_noise)\n","            raw = PHI_meas_train_raw * (1 + noise)\n","            noise = np.apply_along_axis(lambda a: (np.random.normal(scale=1 / np.sqrt(2),\n","                                                                    size=PHI_meas_train_raw.shape[1:]) +\n","                                                   np.random.normal(scale=1 / np.sqrt(2),\n","                                                                    size=PHI_meas_train_raw.shape[1:]) * 1j) * a, 1,\n","                                        meas_add_noise)\n","            raw = raw + np.std(raw, axis=(1, 2)).reshape((-1, 1, 1)) * noise\n","            PHI_meas_training_train[:, :, :(ns_target - 1) * 2] = raw.view('float64')\n","        num_batches = (train_size + batch_size - 1) // batch_size\n","        # if epoch > 0 and epoch % metrics_eval_step == 0:\n","        # hist_avg = {}\n","        # for k, v in history.history.items():\n","        #     if k.startswith('val_'):\n","        #         l = k[4:]\n","        #     else:\n","        #         l = k\n","        #     if l in logger.stateful_metrics:\n","        #         hist_avg[k] = v[-1]\n","        #     else:\n","        #         hist_avg[k] = np.average(v[-metrics_eval_n:])\n","        # img_loss_avg = hist_avg['val_gan_' + gan.metrics_names[0]] - hist_avg['val_gan_' + gan.metrics_names[7]]\n","        # dis_loss_avg = hist_avg['val_discriminator_' + discriminator.metrics_names[0]]\n","        # min_img_loss = np.min(history.history['val_gan_' + gan.metrics_names[0]]) \\\n","        #                - np.min(history.history['val_gan_' + gan.metrics_names[7]])\n","        # if img_loss_avg > min_img_loss_avg * img_loss_baseline_factor:\n","        #     if not augment:\n","        #         augment = True\n","        #     elif img_loss_avg >= img_loss_threshold and min_img_loss >= img_loss_threshold2:\n","        #         soft_label = True\n","        # elif dis_loss_avg > min_dis_loss_avg:\n","        #     if augment:\n","        #         augment = False\n","        #     elif img_loss_avg < img_loss_threshold:\n","        #         soft_label = False\n","        # img_loss_avg = np.average(history.history['val_gan_' + gan.metrics_names[0]][-metrics_eval_n:])\\\n","        #                - np.average(history.history['val_gan_' + gan.metrics_names[7]][-metrics_eval_n:])\n","        # if soft_label and img_loss_avg < img_loss_threshold:\n","        #     soft_label = False\n","        # if np.random.random() > 0.5:\n","        #     augment = not augment\n","        # min_img_loss_avg = min(img_loss_avg, min_img_loss_avg)\n","        # min_dis_loss_avg = min(dis_loss_avg, min_dis_loss_avg)\n","        # if epoch >= init_train:\n","        #     if gan_d_acc[0] < 0.5 or gan_d_acc[1] < 0.5:\n","        #         prob_augment = 0.8\n","        #     else:\n","        #         prob_augment = 0.5\n","        #     if augment == (np.random.random() < prob_augment):\n","        #         augment = not augment\n","        batch_end = 0\n","        # prob_augment = np.random.random()\n","        # if dump:\n","        #     mean_freq = np.zeros(num_batches)\n","        #     std_freq = np.zeros(num_batches)\n","        #     mean_d = np.zeros(num_batches)\n","        #     std_d = np.zeros(num_batches)\n","        #     mean_ns = np.zeros(num_batches)\n","        #     std_ns = np.zeros(num_batches)\n","        #     MUa_loss = np.zeros(num_batches)\n","        #     MUsp_loss = np.zeros(num_batches)\n","        #     augment_arr = np.zeros(num_batches)\n","        #     seq_sz_arr = np.zeros(num_batches)\n","        # for batch_index, batch_MU_training_aug in enumerate(datagen.flow(MU_training_train[index_array_dis[ia]],\n","        #                                                                  batch_size=32, shuffle=False)):\n","        for batch_index in range(num_batches):\n","            # if batch_index >= num_batches:\n","            #     break\n","            augment = np.random.random() < 0.4\n","            batch_start = batch_end\n","            batch_end = min(train_size, batch_end + batch_size)\n","            batch_ids = index_array_dis[ia[batch_start:batch_end]]\n","            batch_seq_len = seq_len_train[batch_ids]\n","            # if dump:\n","            #     augment_arr[batch_index] = augment\n","            #     mean_freq[batch_index] = np.mean(batch_freq)\n","            #     std_freq[batch_index] = np.std(batch_freq)\n","            #     mean_d[batch_index] = np.mean(batch_d)84+1\n","            #     std_d[batch_index] = np.std(batch_d)\n","            #     mean_ns[batch_index] = np.mean(batch_seq_len)\n","            #     std_ns[batch_index] = np.std(batch_seq_len)\n","            #     seq_sz_arr[batch_index] = seq_sz\n","            size = len(batch_ids)\n","            half2 = len(batch_ids)//2\n","            half = len(batch_ids) - half2\n","            batch_logs = {'batch': batch_index, 'size': size}\n","            callbacks.on_batch_begin(batch_index, batch_logs)\n","            MU_gt = [MU_training_train[batch_ids, 0], MU_training_train[batch_ids, 1]]\n","            MU_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_gt]\n","            # sel_prob = np.random.random() >= 0.5\n","            max_seq_len = max(batch_seq_len)\n","            mask = np.random.random((max_seq_len, 1)) >= 0.1\n","            # seq_sel = np.zeros(PHI_meas_training_train.shape[1], dtype='uint8')\n","            # if sel_prob:\n","            #     seq_sel[:max_seq_len] = np.random.random(max_seq_len) >= 0.1\n","            # else:\n","            #     seq_sel[:max_seq_len] = 1\n","            # in_gen = [PHI_meas_training_train[batch_ids][:, seq_sel] * mask[seq_sel], freq_training_train[batch_ids],\n","            #           d_training_train[batch_ids]]\n","            in_gen = [PHI_meas_training_train[batch_ids][:, :max_seq_len]  * mask, freq_training_train[batch_ids],\n","                      d_training_train[batch_ids]]\n","            # batch_pos_data = pos_data_train[batch_ids]\n","            # batch_pos_data2 = np.clip(batch_pos_data + truncnorm.rvs(-2, 2, scale=0.25, size=batch_pos_data.shape),\n","            #                           0, 1)\n","            # batch_inc_areas = inc_areas_train[batch_ids]\n","            # batch_inc_areas2 = batch_inc_areas + batch_inc_areas * truncnorm.rvs(-2, 2, scale=0.25,\n","            #                                                                      size=batch_inc_areas.shape)\n","            if augment:\n","                noise_param = np.random.random(half2)\n","                blur_param = np.random.random(half2)\n","                noise_param *= blur_param\n","                rotate_param = np.random.random(half2) * 360\n","                # MU_gt_aug = [np.concatenate([MU_gt[i][:half], batch_MU_training_aug[half:, [i]]]) for i in range(2)]\n","                MU_gt_aug = [np.copy(im) for im in MU_gt]\n","                # batch_pos_data = batch_pos_data.copy()\n","                # batch_pos_data[half:] = transform_theta(batch_pos_data[half:], rotate_param.reshape((-1, 1)))\n","                for i, bi in enumerate(batch_ids[half:]):\n","                    temp = datagen.apply_transform(MU_gt_aug[0][half+i], {'theta': rotate_param[i]})[0]\n","                    temp = mask_image(temp, MUa_train[bi])\n","                    # temp = temp + temp * np.random.normal(scale=noise_param[i] * 0.5, size=temp.shape)\n","                    temp = temp + temp * truncnorm.rvs(-2, 2, scale=noise_param[i] * 0.5, size=temp.shape)\n","                    temp = gaussian_filter(temp, blur_param[i] * 5.0)\n","                    MU_gt_aug[0][half+i, 0] = mask_image(temp, 0.0)\n","                    temp = datagen.apply_transform(MU_gt_aug[1][half+i], {'theta': rotate_param[i]})[0]\n","                    temp = mask_image(temp, MUsp_train[bi])\n","                    # temp = temp + temp * np.random.normal(scale=noise_param[i] * 0.5, size=temp.shape)\n","                    temp = temp + temp * truncnorm.rvs(-2, 2, scale=0.5, size=temp.shape)\n","                    temp = gaussian_filter(temp, blur_param[i] * 5.0)\n","                    MU_gt_aug[1][half+i, 0] = mask_image(temp, 0.0)\n","                # temp = np.clip(blur_param, prob_param2 / prob_param, 1.0 - prob_param2 / prob_param)\n","                valid = np.concatenate([hard_valid[:half] - 0.05, 0.95 - 0.05 * np.random.random(half2)])\n","                # valid = 1.0 - label_softness * np.random.beta(temp * prob_param, (1.0 - temp) * prob_param)\n","                # if soft_label:\n","                #     fake = label_softness * np.random.random(len(batch_ids))\n","                #     valid = 1.0 - label_softness * np.random.beta(temp * prob_param, (1.0 - temp) * prob_param)\n","                # else:\n","                #     fake = hard_fake[:len(batch_ids)]\n","                #     valid = hard_valid[:len(batch_ids)] - label_softness\n","                # d_loss1 = discriminator.train_on_batch(\n","                #     MU_gt_aug, [valid, batch_pos_data, batch_inc_areas], sample_weight=\n","                #     [np.concatenate([np.ones(half) * 1.2, np.ones(half2) * (size - half * 1.2) / half2]),\n","                #      np.ones(size) * 1.9, np.ones(size) * 1.9])\n","                d_loss1 = discriminator.train_on_batch(\n","                    MU_gt_aug, valid, sample_weight=\n","                    np.concatenate([np.ones(half) * 1.2, np.ones(half2) * (size - half * 1.2) / half2]))\n","            else:\n","                MU_gt_aug = MU_gt\n","                valid = hard_valid[:size] - 0.05\n","                # valid = 1.0 - 0.05 * np.random.random(size)\n","                # valid = 1.0 - label_softness * np.random.random(len(batch_ids))\n","                # valid = 1.0 - label_softness * np.random.beta(prob_param2,\n","                #                                               prob_param - prob_param2, size=len(batch_ids))\n","                # if soft_label:\n","                #     fake = label_softness * np.random.random(len(batch_ids))\n","                #     valid = 1.0 - label_softness * np.random.beta(\n","                #         prob_param2, prob_param - prob_param2, size=len(batch_ids))\n","                # else:\n","                #     fake = hard_fake[:len(batch_ids)]\n","                #     valid = hard_valid[:len(batch_ids)] - label_softness\n","                # d_loss1 = discriminator.train_on_batch(MU_gt_aug, [valid, batch_pos_data, batch_inc_areas],\n","                #                                        sample_weight=[np.ones(size), np.ones(size) * 1.9,\n","                #                                                       np.ones(size) * 1.9])\n","                d_loss1 = discriminator.train_on_batch(MU_gt_aug, valid)\n","            # fake = hard_fake[:size]\n","            fake = 0.05 * np.random.random(size)\n","            # if epoch < init_train:\n","            #     valid -= label_softness * np.random.random(len(batch_ids)) * (init_train - epoch) / init_train\n","            #     fake += label_softness * np.random.random(len(batch_ids)) * (init_train - epoch) / init_train\n","            # d_loss1 = discriminator.train_on_batch([np.concatenate([im1, im2], axis=0)\n","            #                                        for im1, im2 in zip(MU_gt_aug, MU_gt)],\n","            #                                        np.concatenate([valid, hard_valid[:len(batch_ids)]], axis=0),\n","            #                                        sample_weight=np.ones(2 * len(batch_ids)) * 0.5)\n","            # d_loss2 = discriminator.train_on_batch(generator.predict(in_gen)[:2],\n","            #                                        [fake, batch_pos_data2, batch_inc_areas2],\n","            #                                        sample_weight=[np.ones(size), np.ones(size) * 0.1,\n","            #                                                       np.ones(size) * 0.1])\n","            d_loss2 = discriminator.train_on_batch(generator.predict(in_gen)[:2], fake)\n","            # d_loss = discriminator.train_on_batch([np.concatenate([im1, im2], axis=0)\n","            #                                        for im1, im2 in zip(MU_gt_aug, generator.predict(in_gen)[:2])],\n","            #                                       np.concatenate([valid, fake], axis=0))\n","            d_loss = np.zeros(len(discriminator.metrics_names))\n","            for i, l in enumerate(discriminator.metrics_names):\n","                if l in discriminator.stateful_metric_names:\n","                    d_loss[i] = d_loss2[i]\n","                else:\n","                    d_loss[i] = 0.5 * (d_loss1[i] + d_loss2[i])\n","            # for l in discriminator.layers:\n","            #     weights = l.get_weights()\n","            #     weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n","            #     l.set_weights(weights)\n","            batch_ids = index_array_gan[ia[batch_start:batch_end]]\n","            MU_gt = [MU_training_train[batch_ids, 0], MU_training_train[batch_ids, 1]]\n","            MU_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_gt]\n","            # in_gen = [PHI_meas_training_train[batch_ids][:, seq_sel] * mask[seq_sel], freq_training_train[batch_ids],\n","            #           d_training_train[batch_ids]]\n","            in_gen = [PHI_meas_training_train[batch_ids], freq_training_train[batch_ids],\n","                      d_training_train[batch_ids]]\n","            # batch_pos_data = pos_data_train[batch_ids]\n","            # batch_inc_areas = inc_areas_train[batch_ids]\n","            MU_norm_gt = [MU_norm_training_train[batch_ids, 0], MU_norm_training_train[batch_ids, 1]]\n","            MU_norm_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_norm_gt]\n","            # g_loss = gan.train_on_batch(in_gen, [MU_gt[0], MU_gt[1], MU_norm_gt[0], MU_norm_gt[1],\n","            #                                      MUa_train[batch_ids], MUsp_train[batch_ids],\n","            #                                      hard_valid[:size], batch_pos_data, batch_inc_areas])\n","            g_loss = gan.train_on_batch(in_gen, [MU_gt[0], MU_gt[1], MU_norm_gt[0], MU_norm_gt[1],\n","                                                 MUa_train[batch_ids], MUsp_train[batch_ids], hard_valid[:size]])\n","            for l, o in zip(out_labels, np.concatenate([d_loss, d_loss1, d_loss2, g_loss])):\n","                batch_logs[l] = o\n","            callbacks.on_batch_end(batch_index, batch_logs)\n","            if progress_bar is None:\n","                progress_bar = tqdm(total=train_size, desc='Epoch {}/{}'.format(epoch + 1, end), unit='samples')\n","            # if dump:\n","            #     MUa_loss[batch_index] = g_loss[3]\n","            #     MUsp_loss[batch_index] = g_loss[4]\n","            #     progress_bar.set_postfix(train_on_batch=('D loss: dis [r:%g f:%g] aux [r:%g], acc.: dis [r:%.2f%% ' +\n","            #                                              'f:%.2f%%] | [G total_loss: %g, img_loss: %g, d_loss: dis' +\n","            #                                              ' %g aux %g, d_acc.: dis %.2f%% | MUa_contrast_loss:%g,' +\n","            #                                              ' MUsp_contrast_loss:%g | stats: freq [mean:%g std:%g]' +\n","            #                                              ' d [mean:%g std:%g] ns [mean:%g std:%g] size %g') %\n","            #                                             (d_loss1[1], d_loss2[1], d_loss1[2], 100 * d_loss1[3],\n","            #                                              100 * d_loss2[3], g_loss[0], g_loss[0] - g_loss[7]*dis_lw[0] -\n","            #                                              g_loss[8]*dis_lw[1], g_loss[7], g_loss[8],\n","            #                                              100 * g_loss[-2*dis_metrics_len], g_loss[3], g_loss[4],\n","            #                                              mean_freq[batch_index], std_freq[batch_index],\n","            #                                              mean_d[batch_index], std_d[batch_index],\n","            #                                              mean_ns[batch_index], std_ns[batch_index], seq_sz),\n","            #                              augment=augment)\n","            # else:\n","            # progress_bar.set_postfix(train_on_batch=('D loss: dis [r:%g f:%g] pos [r:%g] area [r:%g], acc.: dis ' +\n","            #                                          '[r:%.2f%% f:%.2f%%] | [G total_loss: %g, img_loss: %g, d_loss:' +\n","            #                                          ' dis %g pos %g area %g, d_acc.: dis %.2f%% | MUa_contrast_' +\n","            #                                          'loss:%g, MUsp_contrast_loss:%g') %\n","            #                                         (d_loss1[1], d_loss2[1], d_loss1[2], d_loss1[3], 100 * d_loss1[4],\n","            #                                          100 * d_loss2[4], g_loss[0], g_loss[0] - g_loss[7]*dis_lw[0] -\n","            #                                          g_loss[8]*dis_lw[1] - g_loss[9]*dis_lw[2], g_loss[7], g_loss[8],\n","            #                                          g_loss[9], 100 * g_loss[-2*dis_metrics_len], g_loss[3], g_loss[4]),\n","            #                          augment=augment)\n","            progress_bar.set_postfix(train_on_batch=('D loss: dis [r:%g f:%g], acc.: dis ' +\n","                                                     '[r:%.2f%% f:%.2f%%] | [G total_loss: %g, img_loss: %g, d_loss:' +\n","                                                     ' dis %g, d_acc.: dis %.2f%% | MUa_contrast_' +\n","                                                     'loss:%g, MUsp_contrast_loss:%g') %\n","                                                    (d_loss1[0], d_loss2[0], 100 * d_loss1[1],\n","                                                     100 * d_loss2[1], g_loss[0], g_loss[0] - g_loss[7]*dis_lw[0],\n","                                                     g_loss[7], 100 * g_loss[-1], g_loss[3], g_loss[4]),\n","                                     augment=augment)\n","            progress_bar.update(size)\n","        MU_gt = [MU_training_val[:, np.array([0])], MU_training_val[:, np.array([1])]]\n","        # d_val_loss1 = discriminator.evaluate(MU_gt, [hard_valid, pos_data_val, inc_areas_val],\n","        #                                      batch_size=batch_size, verbose=0)\n","        # d_val_loss2 = discriminator.evaluate(generator.predict(\n","        #     [PHI_meas_training_val, freq_training_val, d_training_val])[:2], [hard_fake, pos_data_val, inc_areas_val],\n","        #                                      batch_size=batch_size, verbose=0)\n","        d_val_loss1 = discriminator.evaluate(MU_gt, hard_valid, batch_size=batch_size, verbose=0)\n","        d_val_loss2 = discriminator.evaluate(generator.predict(\n","            [PHI_meas_training_val, freq_training_val, d_training_val])[:2], hard_fake, batch_size=batch_size,\n","                                             verbose=0)\n","        # d_val_loss = discriminator.evaluate([np.concatenate([im1, im2], axis=0)\n","        #                                      for im1, im2 in zip(MU_gt,\n","        #                                                          generator.predict(PHI_meas_training_val)[:2])],\n","        #                                     np.concatenate([hard_valid, hard_fake], axis=0), verbose=0)\n","        d_val_loss = np.zeros(len(discriminator.metrics_names))\n","        for i, l in enumerate(discriminator.metrics_names):\n","            if l in discriminator.stateful_metric_names:\n","                d_val_loss[i] = d_val_loss2[i]\n","            else:\n","                d_val_loss[i] = 0.5 * (d_val_loss1[i] + d_val_loss2[i])\n","        MU_norm_gt = [MU_norm_training_val[:, np.array([0])], MU_norm_training_val[:, np.array([1])]]\n","        # progress_bar.set_postfix(validate_on_epoch=('D loss: dis [r:%g f:%g] pos [r:%g f:%g] area [r:%g f:%g], ' +\n","        #                                             'acc.: dis [r:%.2f%% f:%.2f%%] validating generator..') %\n","        #                                            (d_val_loss1[1], d_val_loss2[1], d_val_loss1[2], d_val_loss2[2],\n","        #                                             d_val_loss1[3], d_val_loss2[3], 100 * d_val_loss1[4],\n","        #                                             100 * d_val_loss2[4]))\n","        progress_bar.set_postfix(validate_on_epoch=('D loss: dis [r:%g f:%g], ' +\n","                                                    'acc.: dis [r:%.2f%% f:%.2f%%] validating generator..') %\n","                                                   (d_val_loss1[0], d_val_loss2[0], 100 * d_val_loss1[1],\n","                                                    100 * d_val_loss2[1]))\n","        # g_val_loss = gan.evaluate([PHI_meas_training_val, freq_training_val, d_training_val],\n","        #                           [MU_gt[0], MU_gt[1], MU_norm_gt[0], MU_norm_gt[1], MUa_val, MUsp_val, hard_valid,\n","        #                            pos_data_val, inc_areas_val], batch_size=batch_size, verbose=0)\n","        g_val_loss = gan.evaluate([PHI_meas_training_val, freq_training_val, d_training_val],\n","                                  [MU_gt[0], MU_gt[1], MU_norm_gt[0], MU_norm_gt[1], MUa_val, MUsp_val, hard_valid],\n","                                  batch_size=batch_size, verbose=0)\n","        for l, o in zip(out_labels, np.concatenate([d_val_loss, d_val_loss1, d_val_loss2, g_val_loss])):\n","            epoch_logs['val_' + l] = o\n","        # num_batches = (val_size + batch_size - 1) // batch_size\n","        # for batch_index in range(num_batches):\n","        #     batch_start = batch_index * batch_size\n","        #     batch_end = min(val_size, (batch_index + 1) * batch_size)\n","        #     MU_gt = [MU_training_val[batch_start:batch_end, 0], MU_training_val[batch_start:batch_end, 0]]\n","        #     MU_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_gt]\n","        #     d_loss1 = discriminator.test_on_batch(MU_gt, hard_valid[:(batch_end - batch_start)])\n","        #     in_gen = PHI_meas_training_val[batch_start:batch_end]\n","        #     d_loss2 = discriminator.test_on_batch(generator.predict(in_gen)[:2], hard_fake[:(batch_end - batch_start)])\n","        #     d_loss = np.zeros(len(discriminator.metrics_names))\n","        #     for i, l in enumerate(discriminator.metrics_names):\n","        #         if l in discriminator.stateful_metric_names:\n","        #             d_loss[i] = d_loss2[i]\n","        #         else:\n","        #             d_loss[i] = 0.5 * (d_loss1[i] + d_loss2[i])\n","        #     MU_norm_gt = [MU_norm_training_val[batch_start:batch_end, 0],\n","        #                   MU_norm_training_val[batch_start:batch_end, 1]]\n","        #     MU_norm_gt = [im.reshape(im.shape[:1] + (1,) + im.shape[1:]) for im in MU_norm_gt]\n","        #     g_loss = gan.test_on_batch(in_gen, [MU_gt[0], MU_gt[1], MU_norm_gt[0], MU_norm_gt[1],\n","        #                                       MUa_val[batch_start:batch_end], MUsp_val[batch_start:batch_end],\n","        #                                       hard_valid[:(batch_end - batch_start)]])\n","        #     for l, o in zip(out_labels, np.concatenate([d_loss, g_loss])):\n","        #         if l in logger.stateful_metrics:\n","        #             epoch_logs['val_' + l] = o\n","        #         else:\n","        #             if 'val_' + l in epoch_logs:\n","        #                 epoch_logs['val_' + l] += o * (batch_end - batch_start)\n","        #             else:\n","        #                 epoch_logs['val_' + l] = o * (batch_end - batch_start)\n","        #     pbar.set_postfix(validate_on_batch=('[D loss: %g, acc.: %.2f%%] [G total_loss: %g, img_loss: %g, ' +\n","        #                                         'd_loss: %g, d_acc.: %.2f%%]') %\n","        #                                        (d_loss[0], 100 * d_loss[1], g_loss[0], g_loss[0] - g_loss[7],\n","        #                                         g_loss[7], 100 * g_loss[-1]), soft_label=soft_label, augment=augment)\n","        #     pbar.update(batch_end - batch_start)\n","        # for l in out_labels:\n","        #     if l not in logger.stateful_metrics:\n","        #         epoch_logs['val_' + l] /= val_size\n","        callbacks.on_epoch_end(epoch, epoch_logs)\n","        # gan_d_acc[0] = epoch_logs[out_labels[-1]]\n","        # gan_d_acc[1] = epoch_logs['val_' + out_labels[-1]]\n","        # progress_bar.set_postfix(train=('D loss: dis [r:%g f:%g] pos [r:%g] area [r:%g], acc.: dis [r:%.2f%% ' +\n","        #                                 'f:%.2f%%] | [G total_loss: %g, img_loss: %g, d_loss: dis %g pos %g area %g,' +\n","        #                                 ' d_acc.: dis %.2f%% | MUa_contrast_loss:%g, MUsp_contrast_loss:%g') %\n","        #                                (epoch_logs[out_labels[dis_metrics_names_len + 1]],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*2 + 1]],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len + 2]],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len + 3]],\n","        #                                 100 * epoch_logs[out_labels[dis_metrics_names_len + 4]],\n","        #                                 100 * epoch_logs[out_labels[dis_metrics_names_len*2 + 4]],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3]],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3]] -\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3 + 7]]*dis_lw[0] -\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3 + 8]]*dis_lw[1] -\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3 + 9]]*dis_lw[2],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3 + 7]],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3 + 8]],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3 + 9]],\n","        #                                 100 * epoch_logs[out_labels[-2*dis_metrics_len]],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3 + 3]],\n","        #                                 epoch_logs[out_labels[dis_metrics_names_len*3 + 4]]),\n","        #                          validation=('D loss: dis [r:%g f:%g] pos [r:%g f:%g] area [r:%g f:%g], acc.: dis ' +\n","        #                                      '[r:%.2f%% f:%.2f%%] | [G total_loss: %g, img_loss: %g, d_loss: dis ' +\n","        #                                      '%g pos %g area %g, d_acc.: dis %.2f%% | MUa_contrast_loss:%g, ' +\n","        #                                      'MUsp_contrast_loss:%g') %\n","        #                                     (epoch_logs['val_' + out_labels[dis_metrics_names_len + 1]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*2 + 1]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len + 2]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*2 + 2]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len + 3]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*2 + 3]],\n","        #                                      100 * epoch_logs['val_' + out_labels[dis_metrics_names_len + 4]],\n","        #                                      100 * epoch_logs['val_' + out_labels[dis_metrics_names_len*2 + 4]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3]] -\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 7]]*dis_lw[0] -\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 8]]*dis_lw[1] -\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 9]]*dis_lw[2],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 7]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 8]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 9]],\n","        #                                      100 * epoch_logs['val_' + out_labels[-2*dis_metrics_len]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 3]],\n","        #                                      epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 4]]))\n","        progress_bar.set_postfix(train=('D loss: dis [r:%g f:%g], acc.: dis [r:%.2f%% ' +\n","                                        'f:%.2f%%] | [G total_loss: %g, img_loss: %g, d_loss: dis %g,' +\n","                                        ' d_acc.: dis %.2f%% | MUa_contrast_loss:%g, MUsp_contrast_loss:%g') %\n","                                       (epoch_logs[out_labels[dis_metrics_names_len]],\n","                                        epoch_logs[out_labels[dis_metrics_names_len*2]],\n","                                        100 * epoch_logs[out_labels[dis_metrics_names_len + 1]],\n","                                        100 * epoch_logs[out_labels[dis_metrics_names_len*2 + 1]],\n","                                        epoch_logs[out_labels[dis_metrics_names_len*3]],\n","                                        epoch_logs[out_labels[dis_metrics_names_len*3]] -\n","                                        epoch_logs[out_labels[dis_metrics_names_len*3 + 7]]*dis_lw[0],\n","                                        epoch_logs[out_labels[dis_metrics_names_len*3 + 7]],\n","                                        100 * epoch_logs[out_labels[-1]],\n","                                        epoch_logs[out_labels[dis_metrics_names_len*3 + 3]],\n","                                        epoch_logs[out_labels[dis_metrics_names_len*3 + 4]]),\n","                                 validation=('D loss: dis [r:%g f:%g], acc.: dis ' +\n","                                             '[r:%.2f%% f:%.2f%%] | [G total_loss: %g, img_loss: %g, d_loss: dis ' +\n","                                             '%g, d_acc.: dis %.2f%% | MUa_contrast_loss:%g, ' +\n","                                             'MUsp_contrast_loss:%g') %\n","                                            (epoch_logs['val_' + out_labels[dis_metrics_names_len]],\n","                                             epoch_logs['val_' + out_labels[dis_metrics_names_len*2]],\n","                                             100 * epoch_logs['val_' + out_labels[dis_metrics_names_len + 1]],\n","                                             100 * epoch_logs['val_' + out_labels[dis_metrics_names_len*2 + 1]],\n","                                             epoch_logs['val_' + out_labels[dis_metrics_names_len*3]],\n","                                             epoch_logs['val_' + out_labels[dis_metrics_names_len*3]] -\n","                                             epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 7]]*dis_lw[0],\n","                                             epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 7]],\n","                                             100 * epoch_logs['val_' + out_labels[-1]],\n","                                             epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 3]],\n","                                             epoch_logs['val_' + out_labels[dis_metrics_names_len*3 + 4]]))\n","        progress_bar.close()\n","    callbacks.on_train_end()\n","    hist_data = {\n","        'train_start': time_history.train_time_start,\n","        'train_time': time_history.train_time,\n","        'epoch_time': time_history.times,\n","        'history': history.history,\n","        'choice': np.where(choice == 1)[0].tolist()\n","    }\n","    # if dump:\n","    #     return hist_data, (MUa_loss, MUsp_loss, mean_freq, std_freq, mean_d, std_d, mean_ns, std_ns, augment_arr,\n","    #                        seq_sz_arr)\n","    # else:\n","    return hist_data\n","\n","\n","hist_data = run_epoch(100)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /content/drive/My Drive/Workspace Riset Tata/thesis/helper.py:18: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Workspace Riset Tata/thesis/helper.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Workspace Riset Tata/thesis/helper.py:59: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Loading datasets..\n","MAT files loaded.\n","Create dictionaries..\n","Dictionaries created.\n","Prepare measurement data..\n","All datasets loaded.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","Generator model summary:\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, 7)      0                                            \n","__________________________________________________________________________________________________\n","masking_1 (Masking)             (None, None, 7)      0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 512)          405504      masking_1[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 1)            0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 1)            0           input_3[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 514)          0           bidirectional_1[0][0]            \n","                                                                 lambda_2[0][0]                   \n","                                                                 lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 8192)         4218880     concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 64)           32960       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 2, 64, 64)    0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 64)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 64)           32960       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","U-net (Model)                   (None, 2, 64, 64)    224646      reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1)            65          leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 64)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 2, 64, 64)    0           U-net[1][0]                      \n","__________________________________________________________________________________________________\n","MUa_background (Lambda)         (None, 1)            0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","MUsp_background (Dense)         (None, 1)            65          leaky_re_lu_28[0][0]             \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 2, 64, 64)    0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","repeat_vector_1 (RepeatVector)  (None, 4096, 1)      0           MUa_background[0][0]             \n","__________________________________________________________________________________________________\n","repeat_vector_2 (RepeatVector)  (None, 4096, 1)      0           MUsp_background[0][0]            \n","__________________________________________________________________________________________________\n","MUa_contrast_image (Lambda)     (None, 1, 64, 64)    0           lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 1, 64, 64)    0           repeat_vector_1[0][0]            \n","__________________________________________________________________________________________________\n","MUsp_contrast_image (Lambda)    (None, 1, 64, 64)    0           lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_3 (Reshape)             (None, 1, 64, 64)    0           repeat_vector_2[0][0]            \n","__________________________________________________________________________________________________\n","MUa_image (Multiply)            (None, 1, 64, 64)    0           MUa_contrast_image[0][0]         \n","                                                                 reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","MUsp_image (Multiply)           (None, 1, 64, 64)    0           MUsp_contrast_image[0][0]        \n","                                                                 reshape_3[0][0]                  \n","==================================================================================================\n","Total params: 4,915,080\n","Trainable params: 4,913,984\n","Non-trainable params: 1,096\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Discriminator model summary:\n","Model: \"discriminator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            (None, 1, 64, 64)    0                                            \n","__________________________________________________________________________________________________\n","input_6 (InputLayer)            (None, 1, 64, 64)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 16, 32, 32)   272         input_5[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 16, 32, 32)   272         input_6[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 16, 32, 32)   64          conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 16, 32, 32)   64          conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)      (None, 16, 32, 32)   0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_35 (LeakyReLU)      (None, 16, 32, 32)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 32, 16, 16)   8224        leaky_re_lu_29[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 32, 16, 16)   8224        leaky_re_lu_35[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 32, 16, 16)   128         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 32, 16, 16)   128         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_30 (LeakyReLU)      (None, 32, 16, 16)   0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_36 (LeakyReLU)      (None, 32, 16, 16)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 64, 8, 8)     32832       leaky_re_lu_30[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 64, 8, 8)     32832       leaky_re_lu_36[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 64, 8, 8)     256         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 64, 8, 8)     256         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_31 (LeakyReLU)      (None, 64, 8, 8)     0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_37 (LeakyReLU)      (None, 64, 8, 8)     0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 64, 4, 4)     65600       leaky_re_lu_31[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 64, 4, 4)     65600       leaky_re_lu_37[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 64, 4, 4)     256         conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 64, 4, 4)     256         conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_32 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_38 (LeakyReLU)      (None, 64, 4, 4)     0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 64, 2, 2)     65600       leaky_re_lu_32[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 64, 2, 2)     65600       leaky_re_lu_38[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 64, 2, 2)     256         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 64, 2, 2)     256         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)      (None, 64, 2, 2)     0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_39 (LeakyReLU)      (None, 64, 2, 2)     0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 64, 1, 1)     65600       leaky_re_lu_33[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 64, 1, 1)     65600       leaky_re_lu_39[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 64, 1, 1)     256         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 64, 1, 1)     256         conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_34 (LeakyReLU)      (None, 64, 1, 1)     0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_40 (LeakyReLU)      (None, 64, 1, 1)     0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 64)           0           leaky_re_lu_34[0][0]             \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 64)           0           leaky_re_lu_40[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 128)          0           flatten_1[0][0]                  \n","                                                                 flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","discriminator_result (Dense)    (None, 1)            129         concatenate_7[0][0]              \n","==================================================================================================\n","Total params: 478,817\n","Trainable params: 477,601\n","Non-trainable params: 1,216\n","__________________________________________________________________________________________________\n","Generative adversarial network model summary:\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, 7)      0                                            \n","__________________________________________________________________________________________________\n","masking_1 (Masking)             (None, None, 7)      0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 512)          405504      masking_1[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 1)            0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 1)            0           input_3[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 514)          0           bidirectional_1[0][0]            \n","                                                                 lambda_2[0][0]                   \n","                                                                 lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 8192)         4218880     concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 64)           32960       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 2, 64, 64)    0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 64)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 64)           32960       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","U-net (Model)                   (None, 2, 64, 64)    224646      reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1)            65          leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 64)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 2, 64, 64)    0           U-net[1][0]                      \n","__________________________________________________________________________________________________\n","MUa_background (Lambda)         (None, 1)            0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","MUsp_background (Dense)         (None, 1)            65          leaky_re_lu_28[0][0]             \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 2, 64, 64)    0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","repeat_vector_1 (RepeatVector)  (None, 4096, 1)      0           MUa_background[0][0]             \n","__________________________________________________________________________________________________\n","repeat_vector_2 (RepeatVector)  (None, 4096, 1)      0           MUsp_background[0][0]            \n","__________________________________________________________________________________________________\n","MUa_contrast_image (Lambda)     (None, 1, 64, 64)    0           lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 1, 64, 64)    0           repeat_vector_1[0][0]            \n","__________________________________________________________________________________________________\n","MUsp_contrast_image (Lambda)    (None, 1, 64, 64)    0           lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","reshape_3 (Reshape)             (None, 1, 64, 64)    0           repeat_vector_2[0][0]            \n","__________________________________________________________________________________________________\n","MUa_image (Multiply)            (None, 1, 64, 64)    0           MUa_contrast_image[0][0]         \n","                                                                 reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","MUsp_image (Multiply)           (None, 1, 64, 64)    0           MUsp_contrast_image[0][0]        \n","                                                                 reshape_3[0][0]                  \n","__________________________________________________________________________________________________\n","discriminator (Model)           (None, 1)            478817      MUa_image[0][0]                  \n","                                                                 MUsp_image[0][0]                 \n","==================================================================================================\n","Total params: 5,393,897\n","Trainable params: 4,913,984\n","Non-trainable params: 479,913\n","__________________________________________________________________________________________________\n","['loss', 'MUa_image_loss', 'MUsp_image_loss', 'MUa_contrast_image_loss', 'MUsp_contrast_image_loss', 'MUa_background_loss', 'MUsp_background_loss', 'discriminator_loss', 'MUa_image_mean_absolute_error', 'MUa_image_mean_squared_error', 'MUa_image_mean_absolute_percentage_error', 'MUa_image_mean_squared_logarithmic_error', 'MUa_image_logcosh', 'MUa_image_cosine_proximity', 'MUsp_image_mean_absolute_error', 'MUsp_image_mean_squared_error', 'MUsp_image_mean_absolute_percentage_error', 'MUsp_image_mean_squared_logarithmic_error', 'MUsp_image_logcosh', 'MUsp_image_cosine_proximity', 'MUa_contrast_image_mean_absolute_error', 'MUa_contrast_image_mean_squared_error', 'MUa_contrast_image_mean_absolute_percentage_error', 'MUa_contrast_image_mean_squared_logarithmic_error', 'MUa_contrast_image_logcosh', 'MUa_contrast_image_cosine_proximity', 'MUsp_contrast_image_mean_absolute_error', 'MUsp_contrast_image_mean_squared_error', 'MUsp_contrast_image_mean_absolute_percentage_error', 'MUsp_contrast_image_mean_squared_logarithmic_error', 'MUsp_contrast_image_logcosh', 'MUsp_contrast_image_cosine_proximity', 'MUa_background_mean_absolute_error', 'MUa_background_mean_squared_error', 'MUa_background_mean_absolute_percentage_error', 'MUa_background_mean_squared_logarithmic_error', 'MUa_background_logcosh', 'MUa_background_cosine_proximity', 'MUsp_background_mean_absolute_error', 'MUsp_background_mean_squared_error', 'MUsp_background_mean_absolute_percentage_error', 'MUsp_background_mean_squared_logarithmic_error', 'MUsp_background_logcosh', 'MUsp_background_cosine_proximity', 'discriminator_custom_binary_accuracy']\n","['loss', 'custom_binary_accuracy']\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","Epoch 1/100:   0%|          | 0/8000 [00:00<?, ?samples/s, augment=1, train_on_batch=D loss: dis [r:1.2131 f:0.459484], acc.: dis [r:12.50% f:90.62%] | [G total_loss: 19.1345, img_loss: 17.8818, d_loss: dis 1.25269, d_acc.: dis 15.62% | MUa_contrast_loss:1.4023, MUsp_contrast_loss:1.46524]/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","Epoch 1/100: 100%|██████████| 8000/8000 [05:13<00:00, 26.30samples/s, train=D loss: dis [r:0.719094 f:0.441765], acc.: dis [r:57.45% f:96.78%] | [G total_loss: 10.4408, img_loss: 9.42213, d_loss: dis 1.01865, d_acc.: dis 4.61% | MUa_contrast_loss:0.880538, MUsp_contrast_loss:0.876696, validation=D loss: dis [r:0.499708 f:0.887296], acc.: dis [r:100.00% f:0.00%] | [G total_loss: 9.45652, img_loss: 8.9243, d_loss: dis 0.53222, d_acc.: dis 100.00% | MUa_contrast_loss:0.818564, MUsp_contrast_loss:0.846437]\n","Epoch 2/100: 100%|██████████| 8000/8000 [05:18<00:00, 36.41samples/s, train=D loss: dis [r:0.46087 f:0.353395], acc.: dis [r:93.17% f:99.25%] | [G total_loss: 9.75963, img_loss: 8.45212, d_loss: dis 1.30751, d_acc.: dis 0.04% | MUa_contrast_loss:0.787243, MUsp_contrast_loss:0.783812, validation=D loss: dis [r:0.347359 f:1.25222], acc.: dis [r:100.00% f:0.00%] | [G total_loss: 9.20839, img_loss: 8.85207, d_loss: dis 0.356318, d_acc.: dis 100.00% | MUa_contrast_loss:0.816463, MUsp_contrast_loss:0.844301]\n","Epoch 3/100: 100%|██████████| 8000/8000 [05:26<00:00, 19.68samples/s, train=D loss: dis [r:0.388801 f:0.306605], acc.: dis [r:96.89% f:98.58%] | [G total_loss: 9.93862, img_loss: 8.43147, d_loss: dis 1.50714, d_acc.: dis 0.19% | MUa_contrast_loss:0.785729, MUsp_contrast_loss:0.782339, validation=D loss: dis [r:0.344945 f:1.43813], acc.: dis [r:99.95% f:0.00%] | [G total_loss: 9.20592, img_loss: 8.89876, d_loss: dis 0.307164, d_acc.: dis 100.00% | MUa_contrast_loss:0.817516, MUsp_contrast_loss:0.845085]\n","Epoch 4/100: 100%|██████████| 8000/8000 [05:12<00:00, 34.38samples/s, train=D loss: dis [r:0.3935 f:0.328857], acc.: dis [r:96.53% f:96.85%] | [G total_loss: 9.78908, img_loss: 8.24747, d_loss: dis 1.54161, d_acc.: dis 1.04% | MUa_contrast_loss:0.77327, MUsp_contrast_loss:0.770741, validation=D loss: dis [r:0.330057 f:1.3632], acc.: dis [r:100.00% f:0.00%] | [G total_loss: 9.27148, img_loss: 8.93213, d_loss: dis 0.33935, d_acc.: dis 100.00% | MUa_contrast_loss:0.82456, MUsp_contrast_loss:0.854215]\n","Epoch 5/100: 100%|██████████| 8000/8000 [05:22<00:00, 28.85samples/s, train=D loss: dis [r:0.365642 f:0.287463], acc.: dis [r:96.56% f:97.47%] | [G total_loss: 9.48617, img_loss: 7.84835, d_loss: dis 1.63782, d_acc.: dis 6.21% | MUa_contrast_loss:0.732666, MUsp_contrast_loss:0.734902, validation=D loss: dis [r:0.386722 f:1.12165], acc.: dis [r:96.95% f:0.00%] | [G total_loss: 10.0488, img_loss: 9.643, d_loss: dis 0.405853, d_acc.: dis 100.00% | MUa_contrast_loss:0.887551, MUsp_contrast_loss:0.917301]\n","Epoch 6/100: 100%|██████████| 8000/8000 [05:07<00:00, 24.09samples/s, train=D loss: dis [r:0.436569 f:0.386357], acc.: dis [r:90.14% f:88.48%] | [G total_loss: 9.21515, img_loss: 8.16545, d_loss: dis 1.04969, d_acc.: dis 31.90% | MUa_contrast_loss:0.764756, MUsp_contrast_loss:0.771716, validation=D loss: dis [r:0.185393 f:1.95752], acc.: dis [r:97.65% f:0.00%] | [G total_loss: 10.3891, img_loss: 10.1998, d_loss: dis 0.189375, d_acc.: dis 100.00% | MUa_contrast_loss:0.95704, MUsp_contrast_loss:0.992052]\n","Epoch 7/100: 100%|██████████| 8000/8000 [05:09<00:00, 31.85samples/s, train=D loss: dis [r:0.363688 f:0.271696], acc.: dis [r:94.30% f:96.70%] | [G total_loss: 9.14771, img_loss: 7.63266, d_loss: dis 1.51505, d_acc.: dis 16.84% | MUa_contrast_loss:0.711416, MUsp_contrast_loss:0.719785, validation=D loss: dis [r:0.0794097 f:3.03603], acc.: dis [r:100.00% f:0.00%] | [G total_loss: 9.00453, img_loss: 8.93853, d_loss: dis 0.0660038, d_acc.: dis 100.00% | MUa_contrast_loss:0.835574, MUsp_contrast_loss:0.87041]\n","Epoch 8/100: 100%|██████████| 8000/8000 [05:03<00:00, 36.02samples/s, train=D loss: dis [r:0.400561 f:0.348313], acc.: dis [r:92.15% f:90.69%] | [G total_loss: 9.2214, img_loss: 7.82431, d_loss: dis 1.39708, d_acc.: dis 17.31% | MUa_contrast_loss:0.734132, MUsp_contrast_loss:0.746586, validation=D loss: dis [r:0.0701317 f:3.18756], acc.: dis [r:100.00% f:0.00%] | [G total_loss: 9.38359, img_loss: 9.2729, d_loss: dis 0.110692, d_acc.: dis 100.00% | MUa_contrast_loss:0.878111, MUsp_contrast_loss:0.91146]\n","Epoch 9/100: 100%|██████████| 8000/8000 [05:18<00:00, 43.59samples/s, train=D loss: dis [r:0.349025 f:0.280678], acc.: dis [r:94.08% f:94.44%] | [G total_loss: 9.1442, img_loss: 7.53185, d_loss: dis 1.61235, d_acc.: dis 15.09% | MUa_contrast_loss:0.704259, MUsp_contrast_loss:0.716679, validation=D loss: dis [r:0.0223977 f:5.38452], acc.: dis [r:100.00% f:0.00%] | [G total_loss: 10.1816, img_loss: 10.1158, d_loss: dis 0.0658047, d_acc.: dis 100.00% | MUa_contrast_loss:0.94526, MUsp_contrast_loss:0.976517]\n","Epoch 10/100: 100%|██████████| 8000/8000 [05:44<00:00, 26.02samples/s, train=D loss: dis [r:0.389808 f:0.329739], acc.: dis [r:91.88% f:90.05%] | [G total_loss: 8.87233, img_loss: 7.76329, d_loss: dis 1.10905, d_acc.: dis 32.91% | MUa_contrast_loss:0.725439, MUsp_contrast_loss:0.739243, validation=D loss: dis [r:0.178988 f:2.63958], acc.: dis [r:97.35% f:11.00%] | [G total_loss: 9.72049, img_loss: 9.53994, d_loss: dis 0.180554, d_acc.: dis 89.00% | MUa_contrast_loss:0.910808, MUsp_contrast_loss:0.950875]\n","Epoch 11/100: 100%|██████████| 8000/8000 [05:05<00:00, 25.08samples/s, train=D loss: dis [r:0.299261 f:0.210467], acc.: dis [r:97.51% f:98.62%] | [G total_loss: 8.92577, img_loss: 7.1658, d_loss: dis 1.75997, d_acc.: dis 12.39% | MUa_contrast_loss:0.666239, MUsp_contrast_loss:0.67908, validation=D loss: dis [r:0.0341005 f:5.232], acc.: dis [r:100.00% f:0.00%] | [G total_loss: 8.93931, img_loss: 8.88331, d_loss: dis 0.0560086, d_acc.: dis 100.00% | MUa_contrast_loss:0.83608, MUsp_contrast_loss:0.871264]\n","Epoch 12/100: 100%|██████████| 8000/8000 [05:15<00:00, 28.22samples/s, train=D loss: dis [r:0.363386 f:0.303275], acc.: dis [r:91.51% f:91.29%] | [G total_loss: 8.34224, img_loss: 7.36905, d_loss: dis 0.973195, d_acc.: dis 43.64% | MUa_contrast_loss:0.693699, MUsp_contrast_loss:0.709642, validation=D loss: dis [r:0.332394 f:1.95094], acc.: dis [r:90.00% f:0.60%] | [G total_loss: 9.01183, img_loss: 8.79339, d_loss: dis 0.218441, d_acc.: dis 99.40% | MUa_contrast_loss:0.848172, MUsp_contrast_loss:0.884856]\n","Epoch 13/100: 100%|██████████| 8000/8000 [05:08<00:00, 25.48samples/s, train=D loss: dis [r:0.28633 f:0.202823], acc.: dis [r:97.58% f:98.24%] | [G total_loss: 9.01388, img_loss: 6.85081, d_loss: dis 2.16307, d_acc.: dis 2.15% | MUa_contrast_loss:0.648762, MUsp_contrast_loss:0.668176, validation=D loss: dis [r:0.0433918 f:3.90115], acc.: dis [r:100.00% f:8.85%] | [G total_loss: 8.8903, img_loss: 8.70939, d_loss: dis 0.180914, d_acc.: dis 91.15% | MUa_contrast_loss:0.825334, MUsp_contrast_loss:0.863974]\n","Epoch 14/100: 100%|██████████| 8000/8000 [05:10<00:00, 29.24samples/s, train=D loss: dis [r:0.372145 f:0.290716], acc.: dis [r:91.66% f:91.35%] | [G total_loss: 8.23317, img_loss: 7.12431, d_loss: dis 1.10885, d_acc.: dis 37.24% | MUa_contrast_loss:0.677795, MUsp_contrast_loss:0.699853, validation=D loss: dis [r:0.137405 f:4.84289], acc.: dis [r:95.65% f:2.80%] | [G total_loss: 8.67463, img_loss: 8.57372, d_loss: dis 0.100912, d_acc.: dis 97.20% | MUa_contrast_loss:0.823913, MUsp_contrast_loss:0.863482]\n","Epoch 15/100: 100%|██████████| 8000/8000 [05:25<00:00, 23.94samples/s, train=D loss: dis [r:0.381407 f:0.335755], acc.: dis [r:91.50% f:90.00%] | [G total_loss: 8.52747, img_loss: 7.15657, d_loss: dis 1.37091, d_acc.: dis 21.86% | MUa_contrast_loss:0.680179, MUsp_contrast_loss:0.704, validation=D loss: dis [r:0.799089 f:0.738639], acc.: dis [r:38.75% f:46.55%] | [G total_loss: 8.88436, img_loss: 8.21646, d_loss: dis 0.667901, d_acc.: dis 53.45% | MUa_contrast_loss:0.785814, MUsp_contrast_loss:0.827122]\n","Epoch 16/100: 100%|██████████| 8000/8000 [05:07<00:00, 35.91samples/s, train=D loss: dis [r:0.303686 f:0.21467], acc.: dis [r:96.54% f:97.66%] | [G total_loss: 8.75233, img_loss: 7.08187, d_loss: dis 1.67047, d_acc.: dis 11.30% | MUa_contrast_loss:0.660006, MUsp_contrast_loss:0.683503, validation=D loss: dis [r:0.354369 f:1.66011], acc.: dis [r:86.35% f:21.75%] | [G total_loss: 8.4833, img_loss: 8.04252, d_loss: dis 0.440785, d_acc.: dis 78.25% | MUa_contrast_loss:0.753418, MUsp_contrast_loss:0.796073]\n","Epoch 17/100: 100%|██████████| 8000/8000 [05:24<00:00, 27.72samples/s, train=D loss: dis [r:0.270104 f:0.2046], acc.: dis [r:98.14% f:97.84%] | [G total_loss: 8.58168, img_loss: 6.81591, d_loss: dis 1.76577, d_acc.: dis 11.59% | MUa_contrast_loss:0.602983, MUsp_contrast_loss:0.625621, validation=D loss: dis [r:7.09694 f:0.228535], acc.: dis [r:2.65% f:99.50%] | [G total_loss: 12.0338, img_loss: 10.1124, d_loss: dis 1.92134, d_acc.: dis 0.50% | MUa_contrast_loss:0.891059, MUsp_contrast_loss:0.9358]\n","Epoch 18/100: 100%|██████████| 8000/8000 [05:13<00:00, 23.70samples/s, train=D loss: dis [r:0.319035 f:0.227787], acc.: dis [r:95.06% f:96.16%] | [G total_loss: 9.15619, img_loss: 7.49375, d_loss: dis 1.66243, d_acc.: dis 13.26% | MUa_contrast_loss:0.674597, MUsp_contrast_loss:0.69983, validation=D loss: dis [r:0.919359 f:0.836478], acc.: dis [r:60.20% f:48.95%] | [G total_loss: 9.82027, img_loss: 9.04317, d_loss: dis 0.777099, d_acc.: dis 51.05% | MUa_contrast_loss:0.864867, MUsp_contrast_loss:0.905249]\n","Epoch 19/100: 100%|██████████| 8000/8000 [05:26<00:00, 21.44samples/s, train=D loss: dis [r:0.336083 f:0.229484], acc.: dis [r:93.41% f:95.71%] | [G total_loss: 7.71697, img_loss: 6.66574, d_loss: dis 1.05123, d_acc.: dis 44.82% | MUa_contrast_loss:0.630459, MUsp_contrast_loss:0.657526, validation=D loss: dis [r:1.61654 f:0.860818], acc.: dis [r:40.60% f:37.45%] | [G total_loss: 10.0974, img_loss: 9.40979, d_loss: dis 0.687654, d_acc.: dis 62.55% | MUa_contrast_loss:0.880549, MUsp_contrast_loss:0.922391]\n","Epoch 20/100: 100%|██████████| 8000/8000 [05:16<00:00, 36.43samples/s, train=D loss: dis [r:0.30795 f:0.223685], acc.: dis [r:95.26% f:95.79%] | [G total_loss: 7.63856, img_loss: 6.43391, d_loss: dis 1.20464, d_acc.: dis 39.65% | MUa_contrast_loss:0.607381, MUsp_contrast_loss:0.633077, validation=D loss: dis [r:1.95493 f:0.808475], acc.: dis [r:28.45% f:62.40%] | [G total_loss: 9.53119, img_loss: 8.74756, d_loss: dis 0.783635, d_acc.: dis 37.60% | MUa_contrast_loss:0.830439, MUsp_contrast_loss:0.864887]\n","Epoch 21/100: 100%|██████████| 8000/8000 [05:19<00:00, 21.96samples/s, train=D loss: dis [r:0.295974 f:0.211596], acc.: dis [r:95.81% f:96.71%] | [G total_loss: 7.60514, img_loss: 6.1092, d_loss: dis 1.49594, d_acc.: dis 36.66% | MUa_contrast_loss:0.575946, MUsp_contrast_loss:0.602403, validation=D loss: dis [r:3.18774 f:0.200259], acc.: dis [r:7.75% f:96.15%] | [G total_loss: 10.0416, img_loss: 7.51486, d_loss: dis 2.52672, d_acc.: dis 3.85% | MUa_contrast_loss:0.719467, MUsp_contrast_loss:0.76331]\n","Epoch 22/100: 100%|██████████| 8000/8000 [05:01<00:00, 23.56samples/s, train=D loss: dis [r:0.331948 f:0.254719], acc.: dis [r:93.04% f:94.64%] | [G total_loss: 7.42103, img_loss: 6.36371, d_loss: dis 1.05732, d_acc.: dis 49.09% | MUa_contrast_loss:0.59958, MUsp_contrast_loss:0.62934, validation=D loss: dis [r:2.15866 f:0.265276], acc.: dis [r:12.80% f:95.95%] | [G total_loss: 10.2023, img_loss: 7.99496, d_loss: dis 2.20735, d_acc.: dis 4.05% | MUa_contrast_loss:0.752921, MUsp_contrast_loss:0.80478]\n","Epoch 23/100: 100%|██████████| 8000/8000 [05:29<00:00, 20.46samples/s, train=D loss: dis [r:0.396227 f:0.317781], acc.: dis [r:87.95% f:89.90%] | [G total_loss: 7.74321, img_loss: 6.64608, d_loss: dis 1.09713, d_acc.: dis 37.16% | MUa_contrast_loss:0.623217, MUsp_contrast_loss:0.653253, validation=D loss: dis [r:0.305513 f:2.85878], acc.: dis [r:91.70% f:0.25%] | [G total_loss: 11.2535, img_loss: 11.1308, d_loss: dis 0.122676, d_acc.: dis 99.75% | MUa_contrast_loss:1.06224, MUsp_contrast_loss:1.11242]\n","Epoch 24/100: 100%|██████████| 8000/8000 [05:16<00:00, 26.21samples/s, train=D loss: dis [r:0.366845 f:0.280168], acc.: dis [r:91.29% f:92.89%] | [G total_loss: 8.03782, img_loss: 6.59105, d_loss: dis 1.44677, d_acc.: dis 17.54% | MUa_contrast_loss:0.614644, MUsp_contrast_loss:0.646777, validation=D loss: dis [r:1.01342 f:1.08964], acc.: dis [r:62.15% f:16.70%] | [G total_loss: 9.22101, img_loss: 8.68273, d_loss: dis 0.538282, d_acc.: dis 83.30% | MUa_contrast_loss:0.829446, MUsp_contrast_loss:0.874997]\n","Epoch 25/100: 100%|██████████| 8000/8000 [05:18<00:00, 27.56samples/s, train=D loss: dis [r:0.332135 f:0.260139], acc.: dis [r:93.44% f:93.45%] | [G total_loss: 7.97763, img_loss: 6.58473, d_loss: dis 1.3929, d_acc.: dis 24.64% | MUa_contrast_loss:0.624619, MUsp_contrast_loss:0.654313, validation=D loss: dis [r:1.18855 f:1.69996], acc.: dis [r:47.35% f:37.50%] | [G total_loss: 9.8736, img_loss: 9.14361, d_loss: dis 0.729996, d_acc.: dis 62.50% | MUa_contrast_loss:0.877989, MUsp_contrast_loss:0.922577]\n","Epoch 26/100: 100%|██████████| 8000/8000 [05:18<00:00, 21.84samples/s, train=D loss: dis [r:0.327603 f:0.245661], acc.: dis [r:93.58% f:94.95%] | [G total_loss: 8.16303, img_loss: 6.35946, d_loss: dis 1.80358, d_acc.: dis 13.95% | MUa_contrast_loss:0.60459, MUsp_contrast_loss:0.63038, validation=D loss: dis [r:1.6753 f:0.998532], acc.: dis [r:39.85% f:28.75%] | [G total_loss: 8.10019, img_loss: 7.42792, d_loss: dis 0.672277, d_acc.: dis 71.25% | MUa_contrast_loss:0.700696, MUsp_contrast_loss:0.751137]\n","Epoch 27/100: 100%|██████████| 8000/8000 [05:18<00:00, 25.71samples/s, train=D loss: dis [r:0.365165 f:0.281374], acc.: dis [r:90.36% f:92.34%] | [G total_loss: 7.86814, img_loss: 6.35604, d_loss: dis 1.5121, d_acc.: dis 16.65% | MUa_contrast_loss:0.59984, MUsp_contrast_loss:0.629913, validation=D loss: dis [r:0.327969 f:1.72612], acc.: dis [r:82.00% f:37.10%] | [G total_loss: 7.98703, img_loss: 7.41895, d_loss: dis 0.568087, d_acc.: dis 62.90% | MUa_contrast_loss:0.688853, MUsp_contrast_loss:0.74237]\n","Epoch 28/100: 100%|██████████| 8000/8000 [05:27<00:00, 20.51samples/s, train=D loss: dis [r:0.346206 f:0.264141], acc.: dis [r:91.62% f:93.88%] | [G total_loss: 7.48392, img_loss: 6.22004, d_loss: dis 1.26388, d_acc.: dis 30.95% | MUa_contrast_loss:0.587234, MUsp_contrast_loss:0.618443, validation=D loss: dis [r:0.380673 f:2.08604], acc.: dis [r:87.90% f:0.30%] | [G total_loss: 8.63444, img_loss: 8.44257, d_loss: dis 0.191868, d_acc.: dis 99.70% | MUa_contrast_loss:0.797401, MUsp_contrast_loss:0.839679]\n","Epoch 29/100:  34%|███▍      | 2720/8000 [01:42<03:29, 25.20samples/s, augment=1, train_on_batch=D loss: dis [r:0.424685 f:0.191287], acc.: dis [r:90.62% f:100.00%] | [G total_loss: 10.2373, img_loss: 8.92034, d_loss: dis 1.31693, d_acc.: dis 3.12% | MUa_contrast_loss:0.723559, MUsp_contrast_loss:0.99197]ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-2-4d1c930cd637>\", line 645, in <module>\n","    hist_data = run_epoch(100)\n","  File \"<ipython-input-2-4d1c930cd637>\", line 353, in run_epoch\n","    temp = temp + temp * truncnorm.rvs(-2, 2, scale=noise_param[i] * 0.5, size=temp.shape)\n","  File \"/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py\", line 980, in rvs\n","    vals = self._rvs(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py\", line 913, in _rvs\n","    Y = self._ppf(U, *args)\n","  File \"/usr/local/lib/python3.6/dist-packages/scipy/stats/_continuous_distns.py\", line 7163, in _ppf\n","    return _truncnorm_ppf(q, a, b)\n","  File \"/usr/local/lib/python3.6/dist-packages/scipy/stats/_continuous_distns.py\", line 6933, in vf_wrapper\n","    return vf(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\", line 2091, in __call__\n","    return self._vectorize_call(func=func, args=vargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\", line 2167, in _vectorize_call\n","    outputs = ufunc(*inputs)\n","  File \"/usr/local/lib/python3.6/dist-packages/scipy/stats/_continuous_distns.py\", line 7081, in _truncnorm_ppf\n","    delta = _truncnorm_get_delta(a, b)\n","  File \"/usr/local/lib/python3.6/dist-packages/scipy/stats/_continuous_distns.py\", line 6939, in _truncnorm_get_delta\n","    if (a > TRUNCNORM_TAIL_X) or (b < -TRUNCNORM_TAIL_X):\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}]}]}